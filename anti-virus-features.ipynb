{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.16","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceId":12034111,"sourceType":"datasetVersion","datasetId":7572023}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !pip install biopython\n!pip install --upgrade --no-cache-dir biopython\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T10:17:39.945694Z","iopub.execute_input":"2025-06-03T10:17:39.945909Z","iopub.status.idle":"2025-06-03T10:17:46.502042Z","shell.execute_reply.started":"2025-06-03T10:17:39.945885Z","shell.execute_reply":"2025-06-03T10:17:46.500704Z"}},"outputs":[{"name":"stdout","text":"Collecting biopython\n  Downloading biopython-1.85-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/site-packages (from biopython) (2.0.2)\nInstalling collected packages: biopython\nSuccessfully installed biopython-1.85\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"pip install rdkit-pypi\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T10:17:46.503039Z","iopub.execute_input":"2025-06-03T10:17:46.503328Z","iopub.status.idle":"2025-06-03T10:17:53.584142Z","shell.execute_reply.started":"2025-06-03T10:17:46.503297Z","shell.execute_reply":"2025-06-03T10:17:53.582678Z"}},"outputs":[{"name":"stdout","text":"Collecting rdkit-pypi\n  Downloading rdkit_pypi-2022.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.4/29.4 MB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/site-packages (from rdkit-pypi) (2.0.2)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.10/site-packages (from rdkit-pypi) (11.1.0)\nInstalling collected packages: rdkit-pypi\nSuccessfully installed rdkit-pypi-2022.9.5\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-2.2.0+cu118.html\n!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-2.2.0+cu118.html\n!pip install -q torch-geometric","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T10:17:53.585147Z","iopub.execute_input":"2025-06-03T10:17:53.585456Z","iopub.status.idle":"2025-06-03T10:18:11.034182Z","shell.execute_reply.started":"2025-06-03T10:17:53.585423Z","shell.execute_reply":"2025-06-03T10:18:11.032839Z"}},"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import numpy as np\nfrom collections import Counter\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom Bio.Align import substitution_matrices\nfrom sklearn.cluster import KMeans\nfrom scipy.spatial.distance import squareform\nfrom scipy.cluster.hierarchy import linkage, fcluster\nfrom rdkit import Chem\nfrom rdkit.Chem import AllChem\nimport numpy as np\nfrom tqdm import tqdm\nfrom joblib import Parallel, delayed\nimport itertools\nimport torch\nfrom torch_geometric.data import Data\nfrom torch.utils.data import DataLoader\nfrom torch_geometric.data import Batch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch_geometric.nn import GCNConv, global_mean_pool\nfrom torch.utils.data import random_split, DataLoader\nfrom sklearn.metrics import mean_squared_error\nfrom scipy.stats import pearsonr\nimport torch\n\n\n\nblosum62 = substitution_matrices.load('BLOSUM62')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T10:45:35.327485Z","iopub.execute_input":"2025-06-03T10:45:35.327973Z","iopub.status.idle":"2025-06-03T10:45:35.336139Z","shell.execute_reply.started":"2025-06-03T10:45:35.327933Z","shell.execute_reply":"2025-06-03T10:45:35.334961Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"#30\ndef apaac(sequence, lambda_value=10, weight=0.05):\n    \n    # Hydrophobicity (h1) and Hydrophilicity (h2)\n    hydrophobicity = {\n        'A': 0.62,  'C': 0.29,  'D': -0.90, 'E': -0.74, 'F': 1.19,\n        'G': 0.48,  'H': -0.40, 'I': 1.38,  'K': -1.50, 'L': 1.06,\n        'M': 0.64,  'N': -0.78, 'P': 0.12,  'Q': -0.85, 'R': -2.53,\n        'S': -0.18, 'T': -0.05, 'V': 1.08,  'W': 0.81,  'Y': 0.26\n    }\n    \n    hydrophilicity = {\n        'A': -0.50, 'C': -1.00, 'D': 3.00,  'E': 3.00,  'F': -2.50,\n        'G': 0.00,  'H': -0.50, 'I': -1.80, 'K': 3.00,  'L': -1.80,\n        'M': -1.30, 'N': 0.20,  'P': 0.00,  'Q': 0.20,  'R': 3.00,\n        'S': 0.30,  'T': -0.40, 'V': -1.50, 'W': -3.40, 'Y': -2.30\n    }\n    \n    \n    amino_acids = list(hydrophobicity.keys())\n    sequence = sequence.upper()  \n    \n    # Compute standard amino acid composition (AAC)\n    aac = np.array([sequence.count(aa) / len(sequence) for aa in amino_acids])\n\n    # Compute sequence-order correlation factors\n    lambda_correlation = []\n    for i in range(1, lambda_value + 1):\n        sum_corr = 0\n        for j in range(len(sequence) - i):\n            if sequence[j] in amino_acids and sequence[j + i] in amino_acids:\n                h1_corr = (hydrophobicity[sequence[j]] - hydrophobicity[sequence[j + i]])**2\n                h2_corr = (hydrophilicity[sequence[j]] - hydrophilicity[sequence[j + i]])**2\n                sum_corr += (h1_corr + h2_corr) / 2  # Average correlation\n        lambda_correlation.append((sum_corr+1e-7) / ((len(sequence) - i)+1e-7))\n\n    lambda_correlation = np.array(lambda_correlation)\n\n    # Normalize and combine features\n    apaac_vector = np.concatenate((aac * (1 - weight * sum(lambda_correlation)), weight * lambda_correlation))\n    \n    return apaac_vector","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-03T10:18:44.616427Z","iopub.execute_input":"2025-06-03T10:18:44.616849Z","iopub.status.idle":"2025-06-03T10:18:44.627303Z","shell.execute_reply.started":"2025-06-03T10:18:44.616820Z","shell.execute_reply":"2025-06-03T10:18:44.625963Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# seq = \"ACDEFGHIKLMNPQRSTVWYACDEFGHIKLMNPQRSTVWYX\"\n# apaac_vector = apaac(seq)\n# print(\"APAAC Feature Vector:\", apaac_vector)\n# print(\"Feature Vector Length:\", len(apaac_vector))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T19:49:48.258821Z","iopub.execute_input":"2025-06-02T19:49:48.259053Z","iopub.status.idle":"2025-06-02T19:49:48.281372Z","shell.execute_reply.started":"2025-06-02T19:49:48.259034Z","shell.execute_reply":"2025-06-02T19:49:48.280338Z"}},"outputs":[{"name":"stdout","text":"APAAC Feature Vector: [-0.06343104 -0.06343104 -0.06343104 -0.06343104 -0.06343104 -0.06343104\n -0.06343104 -0.06343104 -0.06343104 -0.06343104 -0.06343104 -0.06343104\n -0.06343104 -0.06343104 -0.06343104 -0.06343104 -0.06343104 -0.06343104\n -0.06343104 -0.06343104  0.20651625  0.24157526  0.20727237  0.33520682\n  0.24398625  0.1566355   0.27018647  0.18447924  0.18053359  0.27394452]\nFeature Vector Length: 30\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"#15\ndef ctdd(sequence):\n    secondary_structure = {\n    \"Helix\": set(\"EALMQKRH\"),\n    \"Strand\": set(\"VIYCWFT\"),\n    \"Coil\": set(\"GNPSD\"),\n    }\n\n    ctdd_vector = []\n    sequence_length=len(sequence)\n    for class_name, amino_acids in secondary_structure.items():\n        positions = [i for i, aa in enumerate(sequence) if aa in amino_acids]\n        \n        if not positions:  # If no amino acid of this class is found\n            ctdd_vector.extend([0, 0, 0, 0, 0])\n            continue\n\n        # Calculate the five key positions (first, 25%, 50%, 75%, last)\n        first = positions[0] / sequence_length\n        p25 = positions[int(len(positions) * 0.25)] / sequence_length\n        p50 = positions[int(len(positions) * 0.50)] / sequence_length\n        p75 = positions[int(len(positions) * 0.75)] / sequence_length\n        last = positions[-1] / sequence_length\n\n        ctdd_vector.extend([first, p25, p50, p75, last])\n\n    return ctdd_vector\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T10:18:44.628463Z","iopub.execute_input":"2025-06-03T10:18:44.628773Z","iopub.status.idle":"2025-06-03T10:18:44.643373Z","shell.execute_reply.started":"2025-06-03T10:18:44.628744Z","shell.execute_reply":"2025-06-03T10:18:44.642430Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"seq = \"ACDEFGHIKLMNPQRSTVWYACDEFGHIKLMNPQRSTVWYX\"\nctdd_vector = ctdd(seq)\nprint(\"CTDD Feature Vector:\", ctdd_vector)\nprint(\"Feature Vector Length:\", len(ctdd_vector))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T19:49:48.294357Z","iopub.execute_input":"2025-06-02T19:49:48.294581Z","iopub.status.idle":"2025-06-02T19:49:48.307815Z","shell.execute_reply.started":"2025-06-02T19:49:48.294561Z","shell.execute_reply":"2025-06-02T19:49:48.306670Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"CTDD Feature Vector: [0.0, 0.21951219512195122, 0.4878048780487805, 0.7073170731707317, 0.8292682926829268, 0.024390243902439025, 0.3902439024390244, 0.5121951219512195, 0.8780487804878049, 0.9512195121951219, 0.04878048780487805, 0.2682926829268293, 0.5365853658536586, 0.7560975609756098, 0.8536585365853658]\nFeature Vector Length: 15\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"#343\ndef ctriad(sequence):\n    #Grpups based on their dipoles and side-chain volumes\n    amino_acid_groups = {\n    'A': 1, 'G': 1, 'V': 1,  # Group 1\n    'I': 2, 'L': 2, 'F': 2, 'P': 2,  # Group 2\n    'Y': 3, 'M': 3, 'T': 3, 'S': 3,  # Group 3\n    'H': 4, 'N': 4, 'Q': 4, 'W': 4,  # Group 4\n    'R': 5, 'K': 5,  # Group 5\n    'D': 6, 'E': 6,  # Group 6\n    'C': 7   # Group 7\n     }\n    # Convert sequence to reduced alphabet (group numbers)\n    reduced_seq = [amino_acid_groups[aa] - 1 for aa in sequence if aa in amino_acid_groups]\n    # Extract triads\n    triads = [tuple(reduced_seq[i:i+3]) for i in range(len(reduced_seq) - 2)]\n   \n    # Count occurrences of each triad\n    triad_counts = Counter(triads)\n\n    # Normalize counts\n    total_triads = len(triads)\n    triad_vector = np.zeros((7, 7, 7))  # 7^3 possible triads\n\n    for triad, count in triad_counts.items():\n        triad_vector[triad] = count / total_triads  # Normalize frequency\n\n    return triad_vector.flatten()\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T10:18:44.644486Z","iopub.execute_input":"2025-06-03T10:18:44.644730Z","iopub.status.idle":"2025-06-03T10:18:44.657140Z","shell.execute_reply.started":"2025-06-03T10:18:44.644708Z","shell.execute_reply":"2025-06-03T10:18:44.656256Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"\nseq = \"ACDEFGHIKLMNPQRSTVWYACDEFGHIKLMNPQRSTVWYX\"\nctriad_vector = ctriad(seq)\n\nprint(\"CTriad Feature Vector:\", ctriad_vector)\nprint(\"Feature Vector Length:\", len(ctriad_vector))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T19:49:48.318819Z","iopub.execute_input":"2025-06-02T19:49:48.319047Z","iopub.status.idle":"2025-06-02T19:49:48.333662Z","shell.execute_reply.started":"2025-06-02T19:49:48.319028Z","shell.execute_reply":"2025-06-02T19:49:48.332593Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"CTriad Feature Vector: [0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.05263158 0.05263158\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.05263158\n 0.         0.         0.         0.         0.05263158 0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.05263158 0.         0.         0.         0.         0.\n 0.         0.         0.05263158 0.         0.         0.\n 0.05263158 0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.05263158\n 0.         0.         0.02631579 0.         0.         0.\n 0.         0.         0.         0.         0.05263158 0.\n 0.         0.         0.         0.         0.         0.\n 0.05263158 0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.05263158 0.05263158 0.         0.         0.02631579\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.05263158 0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.05263158 0.         0.         0.         0.\n 0.         0.         0.05263158 0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.05263158 0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.05263158\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.05263158 0.\n 0.         0.         0.         0.         0.         0.\n 0.        ]\nFeature Vector Length: 343\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"#5\ndef get_similarity(seq1, seq2):\n    \"\"\"Compute similarity score between two subsequences using BLOSUM62.\"\"\"\n    return sum(blosum62.get((a, b), blosum62.get((b, a), -4)) for a, b in zip(seq1, seq2))\n\n\ndef extract_subsequences(protein_seqs, k=5):\n    \"\"\"Extract fixed-length k-mers from a list of protein sequences.\"\"\"\n    all_subsequences = set()\n    protein_subsequences = []  # Store k-mers for each protein separately\n\n    for seq in tqdm(protein_seqs,desc='extract_subsequences'):\n        kmers = [seq[i:i+k] for i in range(len(seq) - k + 1)]\n        protein_subsequences.append(kmers)  # Store per protein\n        all_subsequences.update(kmers)  # Collect all k-mers for clustering\n\n    return all_subsequences, protein_subsequences\n\ndef compute_similarity_matrix(subsequences, n_jobs=-1):\n    n = len(subsequences)\n    similarity_matrix = np.zeros((n, n))\n\n    def compute_row(i):\n        row = np.zeros(n)\n        for j in range(i, n):\n            score = get_similarity(subsequences[i], subsequences[j])\n            row[j] = score\n        return i, row\n\n    results = Parallel(n_jobs=n_jobs)(delayed(compute_row)(i) for i in tqdm(range(n), desc=\"Computing rows\"))\n\n    for i, row in results:\n        similarity_matrix[i, i:] = row[i:]\n        similarity_matrix[i:, i] = row[i:]\n\n    return similarity_matrix\n\ndef convert_to_distance_matrix(similarity_matrix):\n    \"\"\"Convert similarity matrix to distance matrix using D(i, j) = 1 - normalized(S(i, j)).\"\"\"\n    distance_matrix = 1 - (similarity_matrix - np.min(similarity_matrix)) / (np.max(similarity_matrix) - np.min(similarity_matrix))\n    np.fill_diagonal(distance_matrix, 0)  # Ensure self-distance is 0\n    return distance_matrix\n\ndef cluster_subsequences(distance_matrix, num_clusters=10):\n    \"\"\"Cluster subsequences using hierarchical clustering.\"\"\"\n    condensed_distance = squareform(distance_matrix)\n    linkage_matrix = linkage(condensed_distance, method='average')\n    cluster_labels = fcluster(linkage_matrix, num_clusters, criterion='maxclust')\n    return cluster_labels\n\ndef generate_feature_vectors(protein_subsequences, cluster_labels, all_subsequences, num_clusters):\n    \"\"\"Generate feature vectors for each protein based on cluster frequencies.\"\"\"\n\n    # Step 1: Map each k-mer to its cluster ID once\n    kmer_to_cluster = {kmer: cluster_labels[i] for i, kmer in enumerate(all_subsequences)}\n\n    feature_vectors = []\n\n    for protein_kmers in tqdm(protein_subsequences, desc='generate_feature_vectors'):\n        cluster_counts = np.zeros(num_clusters)\n\n        for kmer in protein_kmers:\n            cluster_id = kmer_to_cluster.get(kmer)\n            if cluster_id is not None:\n                cluster_counts[cluster_id - 1] += 1  # Assuming cluster IDs are 1-based\n\n        total = cluster_counts.sum()\n        if total > 0:\n            feature_vector = cluster_counts / total\n        else:\n            feature_vector = cluster_counts  # remains zeros\n\n        feature_vectors.append(feature_vector)\n\n    return np.array(feature_vectors)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T10:18:44.660664Z","iopub.execute_input":"2025-06-03T10:18:44.660875Z","iopub.status.idle":"2025-06-03T10:18:44.671953Z","shell.execute_reply.started":"2025-06-03T10:18:44.660853Z","shell.execute_reply":"2025-06-03T10:18:44.671292Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"#400\ndef dde(sequence):\n    \"\"\"Computes the Dipeptide Deviation from Expected Mean (DDE) descriptor for a given protein sequence.\"\"\"\n    \n    amino_acids = 'ACDEFGHIKLMNPQRSTVWY'  \n    dipeptides = [''.join(pair) for pair in itertools.product(amino_acids, repeat=2)]\n    \n    aa_counts = Counter(sequence)\n    L = len(sequence)\n    aa_freq = {aa: aa_counts.get(aa, 0) / L for aa in amino_acids}\n\n    dipeptide_counts = Counter([sequence[i:i+2] for i in range(L-1)])\n    Dc = {dp: dipeptide_counts.get(dp, 0) / (L-1) for dp in dipeptides}\n\n    Tm = {dp: aa_freq[dp[0]] * aa_freq[dp[1]] for dp in dipeptides}\n    Tv = {dp: (Tm[dp] * (1 - Tm[dp])) / L if Tm[dp] > 0 else 0 for dp in dipeptides}\n\n    DDE = {dp: (Dc[dp] - Tm[dp]) / (Tv[dp] ** 0.5) if Tv[dp] > 0 else 0 for dp in dipeptides}\n\n    return DDE.values()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T10:18:44.673044Z","iopub.execute_input":"2025-06-03T10:18:44.673307Z","iopub.status.idle":"2025-06-03T10:18:44.687755Z","shell.execute_reply.started":"2025-06-03T10:18:44.673286Z","shell.execute_reply":"2025-06-03T10:18:44.687017Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"#5\nhydrophobicity_Kyte_Doolittle  = {\n    'A': 1.8,  'C': 2.5,  'D': -3.5, 'E': -3.5, 'F': 2.8,\n    'G': -0.4, 'H': -3.2, 'I': 4.5,  'K': -3.9, 'L': 3.8,\n    'M': 1.9,  'N': -3.5, 'P': -1.6, 'Q': -3.5, 'R': -4.5,\n    'S': -0.8, 'T': -0.7, 'V': 4.2,  'W': -0.9, 'Y': -1.3\n}\n\nHydrophilicity_Hopp_Woods_scale  = {\n    'A': -0.5, 'C': -1.0, 'D': 3.0,  'E': 3.0,  'F': -2.5,\n    'G': 0.0,  'H': -0.5, 'I': -1.8, 'K': 3.0,  'L': -1.8,\n    'M': -1.3, 'N': 0.2,  'P': 0.0,  'Q': 0.2,  'R': 3.0,\n    'S': 0.3,  'T': -0.4, 'V': -1.5, 'W': -3.4, 'Y': -2.3\n}\nPolarity_Scale = {\n    'A': 8.1,  'C': 5.5,  'D': 13.0, 'E': 12.3, 'F': 5.2,\n    'G': 9.0,  'H': 10.4, 'I': 5.2,  'K': 11.3, 'L': 4.9,\n    'M': 5.7,  'N': 11.6, 'P': 8.0,  'Q': 10.5, 'R': 10.5,\n    'S': 9.2,  'T': 8.6,  'V': 5.9,  'W': 5.4,  'Y': 6.2\n}\nMolecular_Weight = {\n    'A': 89.09,  'C': 121.15, 'D': 133.10, 'E': 147.13, 'F': 165.19,\n    'G': 75.07,  'H': 155.16, 'I': 131.17, 'K': 146.19, 'L': 131.17,\n    'M': 149.21, 'N': 132.12, 'P': 115.13, 'Q': 146.15, 'R': 174.20,\n    'S': 105.09, 'T': 119.12, 'V': 117.15, 'W': 204.23, 'Y': 181.19\n}\n\n\n\ndef geary_autocorrelation(sequence, max_lag=5, property_dict=hydrophobicity_Kyte_Doolittle):\n    \n    prop_values = np.array([property_dict.get(aa, 0) for aa in sequence])  # Default 0 if AA is unknown\n    N = len(prop_values)\n    mean_p = np.mean(prop_values)\n\n    geary_values = {}\n    \n    for d in range(1, max_lag + 1):\n        numerator = np.sum((prop_values[:-d] - prop_values[d:]) ** 2)\n        denominator = 2 * (N - d) * np.sum((prop_values - mean_p) ** 2)\n        geary_values[f'Geary_Lag_{d}'] = (N - 1) * numerator / denominator if denominator != 0 else 0\n\n    return geary_values.values()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T10:18:44.689064Z","iopub.execute_input":"2025-06-03T10:18:44.689297Z","iopub.status.idle":"2025-06-03T10:18:44.698698Z","shell.execute_reply.started":"2025-06-03T10:18:44.689274Z","shell.execute_reply":"2025-06-03T10:18:44.697702Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"\n# Read the CSV file\ndf = pd.read_csv(\"/kaggle/input/virus-drug/virus_drug_interactions.csv\")\ndf = df.drop(df.columns[0], axis=1)\n# Display the first few rows\nprint(df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T10:18:44.699666Z","iopub.execute_input":"2025-06-03T10:18:44.699878Z","iopub.status.idle":"2025-06-03T10:18:44.993745Z","shell.execute_reply.started":"2025-06-03T10:18:44.699857Z","shell.execute_reply":"2025-06-03T10:18:44.992691Z"}},"outputs":[{"name":"stdout","text":"                                    Protein_Sequence  \\\n0  PISPIETVPVKLKPGMDGPKVKQWPLTEEKIKALVEICTEMEKEGK...   \n1  MTMDEQQSQAVAPVYVGGFLARYDQSPDEAELLLPRDVVEHWLHAQ...   \n2  PQVTLWQRPLVTIKIGGQLKEALLDTGADDTVLEEMSLPGRWKPKM...   \n3  PQVTLWQRPLVTIKIGGQLKEALLDTGADDTVLEEMSLPGRWKPKM...   \n4  PQVTLWQRPLVTIKIGGQLKEALLDTGADDTVLEEMSLPGRWKPKM...   \n\n                                              SMILES     pIC50  \n0                       S=C(NCN1CCOCC1)Nc1ccc(Br)cn1  5.000000  \n1                  CC(=O)O[C@@H]1CC(=O)N1C(=O)NC(C)C  4.000000  \n2  CCC(C)[C@H](NC(=O)[C@@H]1CCCN1[P@@](=O)(OC)[C@...  7.522879  \n3  CCC(C)[C@H](NC(=O)[C@@H]1CCCN1[P@@](=O)(OC)[C@...  7.031517  \n4  COC(=O)N[C@H](C(=O)N[C@@H](Cc1ccccc1)C(O)CN(Cc...  7.376751  \n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# Example Data\nprotein_sequences = df['Protein_Sequence']\nk = 5\nnum_clusters = 10\n\n# Extract subsequences (k-mers)\nall_subsequences, protein_subsequences = extract_subsequences(protein_sequences, k)\n# Compute similarity and distance matrices\nall_subsequences=list(all_subsequences)\nsimilarity_matrix = compute_similarity_matrix(all_subsequences)\ndistance_matrix = convert_to_distance_matrix(similarity_matrix)\n\n# Cluster the subsequences\nsubsequence_cluster_labels = cluster_subsequences(distance_matrix, num_clusters)\n# Generate feature vectors for each protein\nfeature_vectors = generate_feature_vectors(protein_subsequences, subsequence_cluster_labels, all_subsequences, num_clusters)\n\nprint(len(feature_vectors),len(feature_vectors[0]))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T10:18:44.994976Z","iopub.execute_input":"2025-06-03T10:18:44.995250Z","iopub.status.idle":"2025-06-03T10:39:22.259284Z","shell.execute_reply.started":"2025-06-03T10:18:44.995223Z","shell.execute_reply":"2025-06-03T10:39:22.257756Z"}},"outputs":[{"name":"stderr","text":"extract_subsequences: 100%|██████████| 19451/19451 [00:02<00:00, 8010.05it/s] \nComputing rows: 100%|██████████| 56409/56409 [16:06<00:00, 58.37it/s] \ngenerate_feature_vectors: 100%|██████████| 19451/19451 [00:05<00:00, 3883.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"19451 10\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"def one_hot_encode(value, valid_values):\n    if value not in valid_values:\n        value = valid_values[-1]\n    return [value == item for item in valid_values]\n\n\ndef get_atom_features(atom):\n    atom_symbols = [\n        'C', 'N', 'O', 'S', 'F', 'Si', 'P', 'Cl', 'Br', 'Mg', 'Na', 'Ca',\n        'Fe', 'As', 'Al', 'I', 'B', 'V', 'K', 'Tl', 'Yb', 'Sb', 'Sn',\n        'Ag', 'Pd', 'Co', 'Se', 'Ti', 'Zn', 'H', 'Li', 'Ge', 'Cu', 'Au',\n        'Ni', 'Cd', 'In', 'Mn', 'Zr', 'Cr', 'Pt', 'Hg', 'Pb', 'X'\n    ]\n    degrees = list(range(11))\n    hydrogen_counts = list(range(11))\n    valences = list(range(11))\n\n    features = (\n        one_hot_encode(atom.GetSymbol(), atom_symbols) +\n        one_hot_encode(atom.GetDegree(), degrees) +\n        one_hot_encode(atom.GetTotalNumHs(), hydrogen_counts) +\n        one_hot_encode(atom.GetImplicitValence(), valences) +\n        [atom.GetIsAromatic()]\n    )\n\n    return np.array(features)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T10:46:16.035175Z","iopub.execute_input":"2025-06-03T10:46:16.035604Z","iopub.status.idle":"2025-06-03T10:46:16.042351Z","shell.execute_reply.started":"2025-06-03T10:46:16.035564Z","shell.execute_reply":"2025-06-03T10:46:16.041430Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"def smile_graph(smile):\n    nodes=[]\n    edges=[]\n    edges_type=[]\n    mol = Chem.MolFromSmiles(smile)\n    mol_size = mol.GetNumAtoms()\n    for atom in mol.GetAtoms():\n        nodes.append(get_atom_features(atom))\n    \n    for bond in mol.GetBonds():\n        start = bond.GetBeginAtomIdx()\n        end = bond.GetEndAtomIdx()\n        bond_type = bond.GetBondTypeAsDouble()\n\n        # Since molecular graphs are undirected, add both directions\n        edges.append([start, end])\n        edges.append([end, start])\n\n        edges_type.append(bond_type)\n        edges_type.append(bond_type)\n        \n\n    return mol_size,nodes,edges,edges_type\n\n    # for atom in mol.GetAtoms():\n    #     print(atom.GetIdx(), atom.GetSymbol())\n    # return  Draw.MolToImage(mol)\n    \n   \n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T10:45:47.235690Z","iopub.execute_input":"2025-06-03T10:45:47.236049Z","iopub.status.idle":"2025-06-03T10:45:47.242260Z","shell.execute_reply.started":"2025-06-03T10:45:47.236022Z","shell.execute_reply":"2025-06-03T10:45:47.240930Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"protein_sequences = df['Protein_Sequence']\ndrugs = df['SMILES']\npIC50=df['pIC50']\nprotein_features=[]\ndrug_graphs=[]\nfor i,protein in tqdm(enumerate(protein_sequences)):\n    vec=[]\n    vec.extend(apaac(protein))\n    vec.extend(ctdd(protein))\n    vec.extend(ctriad(protein))\n    vec.extend(dde(protein))\n    vec.extend(geary_autocorrelation(protein))\n    vec.extend(feature_vectors[i])\n\n    protein_features.append(vec)\n    graph=smile_graph(drugs[i])\n    drug_graphs.append(graph)\nprint(len(protein_features),len(protein_features[0]))\nprint(len(drug_graphs),len(drug_graphs[0]))\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T10:46:18.606683Z","iopub.execute_input":"2025-06-03T10:46:18.607076Z","iopub.status.idle":"2025-06-03T10:48:47.916472Z","shell.execute_reply.started":"2025-06-03T10:46:18.607048Z","shell.execute_reply":"2025-06-03T10:48:47.915345Z"}},"outputs":[{"name":"stderr","text":"19451it [02:29, 130.28it/s]\n","output_type":"stream"},{"name":"stdout","text":"19451 803\n19451 4\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"protein_features=np.array(protein_features)\npIC50=np.array(pIC50)\n\nnp.save(\"protein_features.npy\", protein_features)\nnp.save(\"pIC50.npy\", pIC50)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T10:52:32.806761Z","iopub.execute_input":"2025-06-03T10:52:32.807218Z","iopub.status.idle":"2025-06-03T10:52:32.978798Z","shell.execute_reply.started":"2025-06-03T10:52:32.807184Z","shell.execute_reply":"2025-06-03T10:52:32.977585Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"import pickle\n\nwith open(\"drug_graphs.pkl\", \"wb\") as f:\n    pickle.dump(drug_graphs, f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T10:52:59.717284Z","iopub.execute_input":"2025-06-03T10:52:59.717700Z","iopub.status.idle":"2025-06-03T10:53:03.413553Z","shell.execute_reply.started":"2025-06-03T10:52:59.717667Z","shell.execute_reply":"2025-06-03T10:53:03.412291Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"with open(\"/kaggle/working/drug_graphs.pkl\", \"rb\") as f:\n    drug_graphs = pickle.load(f)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T10:54:01.126840Z","iopub.execute_input":"2025-06-03T10:54:01.127226Z","iopub.status.idle":"2025-06-03T10:54:04.556468Z","shell.execute_reply.started":"2025-06-03T10:54:01.127194Z","shell.execute_reply":"2025-06-03T10:54:04.555224Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"18 [array([False, False, False,  True, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n        True, False, False, False, False, False, False, False, False,\n       False,  True, False, False, False, False, False, False, False,\n       False, False, False,  True, False, False, False, False, False,\n       False, False, False, False, False, False]), array([ True, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False,  True, False, False, False, False, False, False,\n       False,  True, False, False, False, False, False, False, False,\n       False, False, False,  True, False, False, False, False, False,\n       False, False, False, False, False, False]), array([False,  True, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False,  True, False, False, False, False, False, False, False,\n       False, False,  True, False, False, False, False, False, False,\n       False, False, False, False,  True, False, False, False, False,\n       False, False, False, False, False, False]), array([ True, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False,  True, False, False, False, False, False, False, False,\n       False, False, False,  True, False, False, False, False, False,\n       False, False, False, False, False,  True, False, False, False,\n       False, False, False, False, False, False]), array([False,  True, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False,  True, False, False, False, False, False, False,\n       False,  True, False, False, False, False, False, False, False,\n       False, False, False,  True, False, False, False, False, False,\n       False, False, False, False, False, False]), array([ True, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False,  True, False, False, False, False, False, False, False,\n       False, False, False,  True, False, False, False, False, False,\n       False, False, False, False, False,  True, False, False, False,\n       False, False, False, False, False, False]), array([ True, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False,  True, False, False, False, False, False, False, False,\n       False, False, False,  True, False, False, False, False, False,\n       False, False, False, False, False,  True, False, False, False,\n       False, False, False, False, False, False]), array([False, False,  True, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False,  True, False, False, False, False, False, False, False,\n       False,  True, False, False, False, False, False, False, False,\n       False, False, False,  True, False, False, False, False, False,\n       False, False, False, False, False, False]), array([ True, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False,  True, False, False, False, False, False, False, False,\n       False, False, False,  True, False, False, False, False, False,\n       False, False, False, False, False,  True, False, False, False,\n       False, False, False, False, False, False]), array([ True, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False,  True, False, False, False, False, False, False, False,\n       False, False, False,  True, False, False, False, False, False,\n       False, False, False, False, False,  True, False, False, False,\n       False, False, False, False, False, False]), array([False,  True, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False,  True, False, False, False, False, False, False, False,\n       False, False,  True, False, False, False, False, False, False,\n       False, False, False, False,  True, False, False, False, False,\n       False, False, False, False, False, False]), array([ True, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False,  True, False, False, False, False, False, False,\n       False,  True, False, False, False, False, False, False, False,\n       False, False, False,  True, False, False, False, False, False,\n       False, False, False, False, False,  True]), array([ True, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False,  True, False, False, False, False, False, False, False,\n       False, False,  True, False, False, False, False, False, False,\n       False, False, False, False,  True, False, False, False, False,\n       False, False, False, False, False,  True]), array([ True, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False,  True, False, False, False, False, False, False, False,\n       False, False,  True, False, False, False, False, False, False,\n       False, False, False, False,  True, False, False, False, False,\n       False, False, False, False, False,  True]), array([ True, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False,  True, False, False, False, False, False, False,\n       False,  True, False, False, False, False, False, False, False,\n       False, False, False,  True, False, False, False, False, False,\n       False, False, False, False, False,  True]), array([False, False, False, False, False, False, False, False,  True,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n        True, False, False, False, False, False, False, False, False,\n       False,  True, False, False, False, False, False, False, False,\n       False, False, False,  True, False, False, False, False, False,\n       False, False, False, False, False, False]), array([ True, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False,  True, False, False, False, False, False, False, False,\n       False, False,  True, False, False, False, False, False, False,\n       False, False, False, False,  True, False, False, False, False,\n       False, False, False, False, False,  True]), array([False,  True, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False,  True, False, False, False, False, False, False, False,\n       False,  True, False, False, False, False, False, False, False,\n       False, False, False,  True, False, False, False, False, False,\n       False, False, False, False, False,  True])] [[0, 1], [1, 0], [1, 2], [2, 1], [2, 3], [3, 2], [3, 4], [4, 3], [4, 5], [5, 4], [5, 6], [6, 5], [6, 7], [7, 6], [7, 8], [8, 7], [8, 9], [9, 8], [1, 10], [10, 1], [10, 11], [11, 10], [11, 12], [12, 11], [12, 13], [13, 12], [13, 14], [14, 13], [14, 15], [15, 14], [14, 16], [16, 14], [16, 17], [17, 16], [9, 4], [4, 9], [17, 11], [11, 17]] [2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.0, 1.0, 1.5, 1.5, 1.5, 1.5, 1.0, 1.0, 1.5, 1.5]\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"def drug_graph_to_data(drug_graph):\n    mol_size, nodes, edges, edges_type = drug_graph\n    x = torch.tensor(nodes, dtype=torch.float)  # [num_nodes, node_features]\n    \n    edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()  # [2, num_edges]\n    edge_attr = torch.tensor(edges_type, dtype=torch.float).unsqueeze(1)  # [num_edges, 1]\n    \n    data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n    return data","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class DrugProteinDataset(torch.utils.data.Dataset):\n    def __init__(self, protein_features, drug_graphs, pIC50_values):\n        self.protein_features = protein_features\n        self.drug_graphs = drug_graphs\n        self.pIC50_values = pIC50_values\n    \n    def __len__(self):\n        return len(self.pIC50_values)\n    \n    def __getitem__(self, idx):\n        protein_feature = torch.tensor(self.protein_features[idx], dtype=torch.float)\n        drug_graph = drug_graph_to_data(self.drug_graphs[idx])\n        pIC50_value = torch.tensor(self.pIC50_values[idx], dtype=torch.float)\n        return protein_feature, drug_graph, pIC50_value\n\ndef custom_collate(batch):\n    protein_feats = torch.stack([item[0] for item in batch])  # [batch_size, protein_feature_dim]\n    drug_graphs = [item[1] for item in batch]                 # List of PyG Data objects\n    labels = torch.stack([item[2] for item in batch])         # [batch_size]\n\n    batch_drug_graphs = Batch.from_data_list(drug_graphs)     # Combine graphs into a single batched graph\n\n    return protein_feats, batch_drug_graphs, labels\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class DrugTargetGNN(nn.Module):\n    def __init__(self, node_feature_dim=-1, protein_feature_dim=-1, hidden_dim=64):\n        super().__init__()\n        # GNN layers for drug graph\n        self.conv1 = GCNConv(node_feature_dim, hidden_dim)\n        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n        \n        # MLP for protein features\n        self.protein_mlp = nn.Sequential(\n            nn.Linear(protein_feature_dim, hidden_dim),\n            nn.ReLU(),\n            nn.Linear(hidden_dim, hidden_dim)\n        )\n        \n        # Final layers for combined features\n        self.final_mlp = nn.Sequential(\n            nn.Linear(hidden_dim * 2, hidden_dim),\n            nn.ReLU(),\n            nn.Linear(hidden_dim, 1)  # regression output for pIC50\n        )\n        \n    def forward(self, protein_feat, drug_graph):\n        # GNN on drug graph\n        x, edge_index = drug_graph.x, drug_graph.edge_index\n        x = F.relu(self.conv1(x, edge_index))\n        x = F.relu(self.conv2(x, edge_index))\n        x = global_mean_pool(x, drug_graph.batch)  # [batch_size, hidden_dim]\n        \n        # Protein feature embedding\n        p = self.protein_mlp(protein_feat)  # [batch_size, hidden_dim]\n        \n        # Combine embeddings\n        combined = torch.cat([x, p], dim=1)\n        out = self.final_mlp(combined)\n        return out.squeeze()  # [batch_size]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ndataset = DrugProteinDataset(protein_features, drug_graphs, pIC50)\ntotal_size = len(dataset)\ntrain_size = int(0.7 * total_size)\nval_size = int(0.15 * total_size)\ntest_size = total_size - train_size - val_size  # ensure no rounding issues\n\ntrain_dataset, val_dataset, test_dataset = random_split(\n    dataset,\n    [train_size, val_size, test_size],\n    generator=torch.Generator().manual_seed(42)  # for reproducibility\n)\n\ntrain_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, collate_fn=custom_collate)\nval_loader = DataLoader(val_dataset, batch_size=128, shuffle=False, collate_fn=custom_collate)\ntest_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, collate_fn=custom_collate)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = DrugTargetGNN(protein_feature_dim=len(protein_features[0])).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\ncriterion = nn.MSELoss()  # for regression\n\nmodel.train()\nfor epoch in range(20):\n    total_loss = 0\n    for protein_feat, drug_graph, values in train_loader:\n        protein_feat = protein_feat.to(device)\n        drug_graph = drug_graph.to(device)\n        values = values.to(device)\n\n        optimizer.zero_grad()\n        outputs = model(protein_feat, drug_graph)\n        loss = criterion(outputs, values)\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n\n    avg_loss = total_loss / len(train_loader)\n    print(f\"Epoch {epoch+1}, Loss: {avg_loss:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ndef evaluate(model, dataloader, device):\n    model.eval()\n    all_preds = []\n    all_labels = []\n\n    with torch.no_grad():\n        for protein_feats, drug_graphs, values in dataloader:\n            protein_feats = protein_feats.to(device)\n            drug_graphs = drug_graphs.to(device)\n            labels = labels.to(device)\n\n            outputs = model(protein_feats, drug_graphs)\n            all_preds.append(outputs.cpu())\n            all_labels.append(labels.cpu())\n\n    preds = torch.cat(all_preds).numpy()\n    labels = torch.cat(all_labels).numpy()\n\n    mse = mean_squared_error(values, preds)\n    rmse = mse ** 0.5\n    pearson_corr, _ = pearsonr(values, preds)\n\n    return {\n        \"MSE\": mse,\n        \"RMSE\": rmse,\n        \"Pearson\": pearson_corr\n    }\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\nval_metrics = evaluate(model, val_loader, device)\nprint(\"Validation Metrics:\", val_metrics)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}