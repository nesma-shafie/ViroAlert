{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12034111,"sourceType":"datasetVersion","datasetId":7572023}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install --upgrade --no-cache-dir biopython\n!pip install rdkit-pypi\n!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-2.2.0+cu118.html\n!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-2.2.0+cu118.html\n!pip install -q torch-geometric\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-03T11:29:17.172733Z","iopub.execute_input":"2025-06-03T11:29:17.173139Z","iopub.status.idle":"2025-06-03T11:29:43.819117Z","shell.execute_reply.started":"2025-06-03T11:29:17.173109Z","shell.execute_reply":"2025-06-03T11:29:43.817955Z"}},"outputs":[{"name":"stdout","text":"Collecting biopython\n  Downloading biopython-1.85-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from biopython) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->biopython) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->biopython) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->biopython) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->biopython) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->biopython) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->biopython) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->biopython) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->biopython) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->biopython) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->biopython) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->biopython) (2024.2.0)\nDownloading biopython-1.85-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: biopython\nSuccessfully installed biopython-1.85\nCollecting rdkit-pypi\n  Downloading rdkit_pypi-2022.9.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rdkit-pypi) (1.26.4)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from rdkit-pypi) (11.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit-pypi) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit-pypi) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit-pypi) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit-pypi) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit-pypi) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit-pypi) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rdkit-pypi) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rdkit-pypi) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->rdkit-pypi) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->rdkit-pypi) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->rdkit-pypi) (2024.2.0)\nDownloading rdkit_pypi-2022.9.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.4/29.4 MB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: rdkit-pypi\nSuccessfully installed rdkit-pypi-2022.9.5\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m69.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m:01\u001b[0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import numpy as np\nfrom collections import Counter\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom Bio.Align import substitution_matrices\nfrom sklearn.cluster import KMeans\nfrom scipy.spatial.distance import squareform\nfrom scipy.cluster.hierarchy import linkage, fcluster\nfrom rdkit import Chem\nfrom rdkit.Chem import AllChem\nfrom tqdm import tqdm\nfrom joblib import Parallel, delayed\nimport itertools\nimport pickle\nblosum62 = substitution_matrices.load('BLOSUM62')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T11:29:47.664611Z","iopub.execute_input":"2025-06-03T11:29:47.665104Z","iopub.status.idle":"2025-06-03T11:29:47.673221Z","shell.execute_reply.started":"2025-06-03T11:29:47.665078Z","shell.execute_reply":"2025-06-03T11:29:47.672334Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"#30\ndef apaac(sequence, lambda_value=10, weight=0.05):\n    \n    # Hydrophobicity (h1) and Hydrophilicity (h2)\n    hydrophobicity = {\n        'A': 0.62,  'C': 0.29,  'D': -0.90, 'E': -0.74, 'F': 1.19,\n        'G': 0.48,  'H': -0.40, 'I': 1.38,  'K': -1.50, 'L': 1.06,\n        'M': 0.64,  'N': -0.78, 'P': 0.12,  'Q': -0.85, 'R': -2.53,\n        'S': -0.18, 'T': -0.05, 'V': 1.08,  'W': 0.81,  'Y': 0.26\n    }\n    \n    hydrophilicity = {\n        'A': -0.50, 'C': -1.00, 'D': 3.00,  'E': 3.00,  'F': -2.50,\n        'G': 0.00,  'H': -0.50, 'I': -1.80, 'K': 3.00,  'L': -1.80,\n        'M': -1.30, 'N': 0.20,  'P': 0.00,  'Q': 0.20,  'R': 3.00,\n        'S': 0.30,  'T': -0.40, 'V': -1.50, 'W': -3.40, 'Y': -2.30\n    }\n    \n    \n    amino_acids = list(hydrophobicity.keys())\n    sequence = sequence.upper()  \n    \n    # Compute standard amino acid composition (AAC)\n    aac = np.array([sequence.count(aa) / len(sequence) for aa in amino_acids])\n\n    # Compute sequence-order correlation factors\n    lambda_correlation = []\n    for i in range(1, lambda_value + 1):\n        sum_corr = 0\n        for j in range(len(sequence) - i):\n            if sequence[j] in amino_acids and sequence[j + i] in amino_acids:\n                h1_corr = (hydrophobicity[sequence[j]] - hydrophobicity[sequence[j + i]])**2\n                h2_corr = (hydrophilicity[sequence[j]] - hydrophilicity[sequence[j + i]])**2\n                sum_corr += (h1_corr + h2_corr) / 2  # Average correlation\n        lambda_correlation.append((sum_corr+1e-7) / ((len(sequence) - i)+1e-7))\n\n    lambda_correlation = np.array(lambda_correlation)\n\n    # Normalize and combine features\n    apaac_vector = np.concatenate((aac * (1 - weight * sum(lambda_correlation)), weight * lambda_correlation))\n    \n    return apaac_vector","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T11:29:48.903801Z","iopub.execute_input":"2025-06-03T11:29:48.904121Z","iopub.status.idle":"2025-06-03T11:29:48.914670Z","shell.execute_reply.started":"2025-06-03T11:29:48.904099Z","shell.execute_reply":"2025-06-03T11:29:48.913540Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"#15\ndef ctdd(sequence):\n    secondary_structure = {\n    \"Helix\": set(\"EALMQKRH\"),\n    \"Strand\": set(\"VIYCWFT\"),\n    \"Coil\": set(\"GNPSD\"),\n    }\n\n    ctdd_vector = []\n    sequence_length=len(sequence)\n    for class_name, amino_acids in secondary_structure.items():\n        positions = [i for i, aa in enumerate(sequence) if aa in amino_acids]\n        \n        if not positions:  # If no amino acid of this class is found\n            ctdd_vector.extend([0, 0, 0, 0, 0])\n            continue\n\n        # Calculate the five key positions (first, 25%, 50%, 75%, last)\n        first = positions[0] / sequence_length\n        p25 = positions[int(len(positions) * 0.25)] / sequence_length\n        p50 = positions[int(len(positions) * 0.50)] / sequence_length\n        p75 = positions[int(len(positions) * 0.75)] / sequence_length\n        last = positions[-1] / sequence_length\n\n        ctdd_vector.extend([first, p25, p50, p75, last])\n\n    return ctdd_vector\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T11:29:49.201525Z","iopub.execute_input":"2025-06-03T11:29:49.201979Z","iopub.status.idle":"2025-06-03T11:29:49.209331Z","shell.execute_reply.started":"2025-06-03T11:29:49.201952Z","shell.execute_reply":"2025-06-03T11:29:49.208382Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"#343\ndef ctriad(sequence):\n    #Grpups based on their dipoles and side-chain volumes\n    amino_acid_groups = {\n    'A': 1, 'G': 1, 'V': 1,  # Group 1\n    'I': 2, 'L': 2, 'F': 2, 'P': 2,  # Group 2\n    'Y': 3, 'M': 3, 'T': 3, 'S': 3,  # Group 3\n    'H': 4, 'N': 4, 'Q': 4, 'W': 4,  # Group 4\n    'R': 5, 'K': 5,  # Group 5\n    'D': 6, 'E': 6,  # Group 6\n    'C': 7   # Group 7\n     }\n    # Convert sequence to reduced alphabet (group numbers)\n    reduced_seq = [amino_acid_groups[aa] - 1 for aa in sequence if aa in amino_acid_groups]\n    # Extract triads\n    triads = [tuple(reduced_seq[i:i+3]) for i in range(len(reduced_seq) - 2)]\n   \n    # Count occurrences of each triad\n    triad_counts = Counter(triads)\n\n    # Normalize counts\n    total_triads = len(triads)\n    triad_vector = np.zeros((7, 7, 7))  # 7^3 possible triads\n\n    for triad, count in triad_counts.items():\n        triad_vector[triad] = count / total_triads  # Normalize frequency\n\n    return triad_vector.flatten()\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T11:29:49.476854Z","iopub.execute_input":"2025-06-03T11:29:49.477178Z","iopub.status.idle":"2025-06-03T11:29:49.484833Z","shell.execute_reply.started":"2025-06-03T11:29:49.477156Z","shell.execute_reply":"2025-06-03T11:29:49.483424Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"#10\ndef get_similarity(seq1, seq2):\n    \"\"\"Compute similarity score between two subsequences using BLOSUM62.\"\"\"\n    return sum(blosum62.get((a, b), blosum62.get((b, a), -4)) for a, b in zip(seq1, seq2))\n\n\ndef extract_subsequences(protein_seqs, k=5):\n    \"\"\"Extract fixed-length k-mers from a list of protein sequences.\"\"\"\n    all_subsequences = set()\n    protein_subsequences = []  # Store k-mers for each protein separately\n\n    for seq in tqdm(protein_seqs,desc='extract_subsequences'):\n        kmers = [seq[i:i+k] for i in range(len(seq) - k + 1)]\n        protein_subsequences.append(kmers)  # Store per protein\n        all_subsequences.update(kmers)  # Collect all k-mers for clustering\n\n    return all_subsequences, protein_subsequences\n\ndef compute_similarity_matrix(subsequences, n_jobs=-1):\n    n = len(subsequences)\n    similarity_matrix = np.zeros((n, n))\n\n    def compute_row(i):\n        row = np.zeros(n)\n        for j in range(i, n):\n            score = get_similarity(subsequences[i], subsequences[j])\n            row[j] = score\n        return i, row\n\n    results = Parallel(n_jobs=n_jobs)(delayed(compute_row)(i) for i in tqdm(range(n), desc=\"Computing rows\"))\n\n    for i, row in results:\n        similarity_matrix[i, i:] = row[i:]\n        similarity_matrix[i:, i] = row[i:]\n\n    return similarity_matrix\n\ndef convert_to_distance_matrix(similarity_matrix):\n    \"\"\"Convert similarity matrix to distance matrix using D(i, j) = 1 - normalized(S(i, j)).\"\"\"\n    distance_matrix = 1 - (similarity_matrix - np.min(similarity_matrix)) / (np.max(similarity_matrix) - np.min(similarity_matrix))\n    np.fill_diagonal(distance_matrix, 0)  # Ensure self-distance is 0\n    return distance_matrix\n\ndef cluster_subsequences(distance_matrix, num_clusters=10):\n    \"\"\"Cluster subsequences using hierarchical clustering.\"\"\"\n    condensed_distance = squareform(distance_matrix)\n    linkage_matrix = linkage(condensed_distance, method='average')\n    cluster_labels = fcluster(linkage_matrix, num_clusters, criterion='maxclust')\n    return cluster_labels\n\ndef generate_feature_vectors(protein_subsequences, cluster_labels, all_subsequences, num_clusters):\n    \"\"\"Generate feature vectors for each protein based on cluster frequencies.\"\"\"\n\n    # Step 1: Map each k-mer to its cluster ID once\n    kmer_to_cluster = {kmer: cluster_labels[i] for i, kmer in enumerate(all_subsequences)}\n\n    feature_vectors = []\n\n    for protein_kmers in tqdm(protein_subsequences, desc='generate_feature_vectors'):\n        cluster_counts = np.zeros(num_clusters)\n\n        for kmer in protein_kmers:\n            cluster_id = kmer_to_cluster.get(kmer)\n            if cluster_id is not None:\n                cluster_counts[cluster_id - 1] += 1  # Assuming cluster IDs are 1-based\n\n        total = cluster_counts.sum()\n        if total > 0:\n            feature_vector = cluster_counts / total\n        else:\n            feature_vector = cluster_counts  # remains zeros\n\n        feature_vectors.append(feature_vector)\n\n    return np.array(feature_vectors)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T11:29:49.746763Z","iopub.execute_input":"2025-06-03T11:29:49.747823Z","iopub.status.idle":"2025-06-03T11:29:49.760511Z","shell.execute_reply.started":"2025-06-03T11:29:49.747750Z","shell.execute_reply":"2025-06-03T11:29:49.759353Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"#400\ndef dde(sequence):\n    \"\"\"Computes the Dipeptide Deviation from Expected Mean (DDE) descriptor for a given protein sequence.\"\"\"\n    \n    amino_acids = 'ACDEFGHIKLMNPQRSTVWY'  \n    dipeptides = [''.join(pair) for pair in itertools.product(amino_acids, repeat=2)]\n    \n    aa_counts = Counter(sequence)\n    L = len(sequence)\n    aa_freq = {aa: aa_counts.get(aa, 0) / L for aa in amino_acids}\n\n    dipeptide_counts = Counter([sequence[i:i+2] for i in range(L-1)])\n    Dc = {dp: dipeptide_counts.get(dp, 0) / (L-1) for dp in dipeptides}\n\n    Tm = {dp: aa_freq[dp[0]] * aa_freq[dp[1]] for dp in dipeptides}\n    Tv = {dp: (Tm[dp] * (1 - Tm[dp])) / L if Tm[dp] > 0 else 0 for dp in dipeptides}\n\n    DDE = {dp: (Dc[dp] - Tm[dp]) / (Tv[dp] ** 0.5) if Tv[dp] > 0 else 0 for dp in dipeptides}\n\n    return DDE.values()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T11:29:51.118246Z","iopub.execute_input":"2025-06-03T11:29:51.118569Z","iopub.status.idle":"2025-06-03T11:29:51.126688Z","shell.execute_reply.started":"2025-06-03T11:29:51.118544Z","shell.execute_reply":"2025-06-03T11:29:51.125705Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"#5\nhydrophobicity_Kyte_Doolittle  = {\n    'A': 1.8,  'C': 2.5,  'D': -3.5, 'E': -3.5, 'F': 2.8,\n    'G': -0.4, 'H': -3.2, 'I': 4.5,  'K': -3.9, 'L': 3.8,\n    'M': 1.9,  'N': -3.5, 'P': -1.6, 'Q': -3.5, 'R': -4.5,\n    'S': -0.8, 'T': -0.7, 'V': 4.2,  'W': -0.9, 'Y': -1.3\n}\n\nHydrophilicity_Hopp_Woods_scale  = {\n    'A': -0.5, 'C': -1.0, 'D': 3.0,  'E': 3.0,  'F': -2.5,\n    'G': 0.0,  'H': -0.5, 'I': -1.8, 'K': 3.0,  'L': -1.8,\n    'M': -1.3, 'N': 0.2,  'P': 0.0,  'Q': 0.2,  'R': 3.0,\n    'S': 0.3,  'T': -0.4, 'V': -1.5, 'W': -3.4, 'Y': -2.3\n}\nPolarity_Scale = {\n    'A': 8.1,  'C': 5.5,  'D': 13.0, 'E': 12.3, 'F': 5.2,\n    'G': 9.0,  'H': 10.4, 'I': 5.2,  'K': 11.3, 'L': 4.9,\n    'M': 5.7,  'N': 11.6, 'P': 8.0,  'Q': 10.5, 'R': 10.5,\n    'S': 9.2,  'T': 8.6,  'V': 5.9,  'W': 5.4,  'Y': 6.2\n}\nMolecular_Weight = {\n    'A': 89.09,  'C': 121.15, 'D': 133.10, 'E': 147.13, 'F': 165.19,\n    'G': 75.07,  'H': 155.16, 'I': 131.17, 'K': 146.19, 'L': 131.17,\n    'M': 149.21, 'N': 132.12, 'P': 115.13, 'Q': 146.15, 'R': 174.20,\n    'S': 105.09, 'T': 119.12, 'V': 117.15, 'W': 204.23, 'Y': 181.19\n}\n\n\n\ndef geary_autocorrelation(sequence, max_lag=5, property_dict=hydrophobicity_Kyte_Doolittle):\n    \n    prop_values = np.array([property_dict.get(aa, 0) for aa in sequence])  # Default 0 if AA is unknown\n    N = len(prop_values)\n    mean_p = np.mean(prop_values)\n\n    geary_values = {}\n    \n    for d in range(1, max_lag + 1):\n        numerator = np.sum((prop_values[:-d] - prop_values[d:]) ** 2)\n        denominator = 2 * (N - d) * np.sum((prop_values - mean_p) ** 2)\n        geary_values[f'Geary_Lag_{d}'] = (N - 1) * numerator / denominator if denominator != 0 else 0\n\n    return geary_values.values()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T11:29:52.415860Z","iopub.execute_input":"2025-06-03T11:29:52.416184Z","iopub.status.idle":"2025-06-03T11:29:52.426743Z","shell.execute_reply.started":"2025-06-03T11:29:52.416161Z","shell.execute_reply":"2025-06-03T11:29:52.425838Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"protein_sequences = df['Protein_Sequence']\nk = 5\nnum_clusters = 10\n# Extract subsequences (k-mers)\nall_subsequences, protein_subsequences = extract_subsequences(protein_sequences, k)\n# Compute similarity and distance matrices\nall_subsequences=list(all_subsequences)\nsimilarity_matrix = compute_similarity_matrix(all_subsequences)\ndistance_matrix = convert_to_distance_matrix(similarity_matrix)\n\n# Cluster the subsequences\nsubsequence_cluster_labels = cluster_subsequences(distance_matrix, num_clusters)\n# Generate feature vectors for each protein\nfeature_vectors = generate_feature_vectors(protein_subsequences, subsequence_cluster_labels, all_subsequences, num_clusters)\n\nprint(len(feature_vectors),len(feature_vectors[0]))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T11:29:54.181553Z","iopub.execute_input":"2025-06-03T11:29:54.181999Z","execution_failed":"2025-06-03T11:31:27.697Z"}},"outputs":[{"name":"stderr","text":"extract_subsequences: 100%|██████████| 19451/19451 [00:02<00:00, 7268.26it/s]\nComputing rows:   0%|          | 164/56409 [01:30<8:29:24,  1.84it/s]","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# Read the CSV file\ndf = pd.read_csv(\"/kaggle/input/virus-drug/virus_drug_interactions.csv\")\ndf = df.drop(df.columns[0], axis=1)\n# Display the first few rows\nprint(df.head())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"protein_sequences = df['Protein_Sequence']\npIC50=df['pIC50']\nprotein_features=[]\nfor i,protein in tqdm(enumerate(protein_sequences)):\n    vec=[]\n    vec.extend(apaac(protein))\n    vec.extend(ctdd(protein))\n    vec.extend(ctriad(protein))\n    vec.extend(dde(protein))\n    vec.extend(geary_autocorrelation(protein))\n    vec.extend(feature_vectors[i])\n    protein_features.append(vec)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"protein_features=np.array(protein_features)\npIC50=np.array(pIC50)\n\nnp.save(\"protein_features.npy\", protein_features)\nnp.save(\"pIC50.npy\", pIC50)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}