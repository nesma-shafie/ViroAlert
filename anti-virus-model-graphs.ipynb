{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceType":"datasetVersion","sourceId":12050961,"datasetId":7581212,"databundleVersionId":12574426},{"sourceType":"datasetVersion","sourceId":12034111,"datasetId":7572023,"databundleVersionId":12555663}],"dockerImageVersionId":31042,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !pip install biopython\n!pip install --upgrade --no-cache-dir biopython\n!pip install rdkit-pypi\n!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-2.2.0+cu118.html\n!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-2.2.0+cu118.html\n!pip install -q torch-geometric\n!pip install fair-esm\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T20:56:09.043780Z","iopub.execute_input":"2025-06-03T20:56:09.043972Z","iopub.status.idle":"2025-06-03T20:56:38.078315Z","shell.execute_reply.started":"2025-06-03T20:56:09.043956Z","shell.execute_reply":"2025-06-03T20:56:38.077443Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Collecting biopython\n  Downloading biopython-1.85-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from biopython) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->biopython) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->biopython) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->biopython) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->biopython) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->biopython) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->biopython) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->biopython) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->biopython) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->biopython) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->biopython) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->biopython) (2024.2.0)\nDownloading biopython-1.85-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: biopython\nSuccessfully installed biopython-1.85\nCollecting rdkit-pypi\n  Downloading rdkit_pypi-2022.9.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rdkit-pypi) (1.26.4)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from rdkit-pypi) (11.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit-pypi) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit-pypi) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit-pypi) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit-pypi) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit-pypi) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit-pypi) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rdkit-pypi) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rdkit-pypi) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->rdkit-pypi) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->rdkit-pypi) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->rdkit-pypi) (2024.2.0)\nDownloading rdkit_pypi-2022.9.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.4/29.4 MB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: rdkit-pypi\nSuccessfully installed rdkit-pypi-2022.9.5\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hCollecting fair-esm\n  Downloading fair_esm-2.0.0-py3-none-any.whl.metadata (37 kB)\nDownloading fair_esm-2.0.0-py3-none-any.whl (93 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: fair-esm\nSuccessfully installed fair-esm-2.0.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom tqdm import tqdm\nimport torch\nfrom torch_geometric.data import Data\nfrom torch_geometric.data import Batch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch_geometric.nn import GCNConv, global_mean_pool\nfrom sklearn.metrics import mean_squared_error\nfrom scipy.stats import pearsonr\nimport pickle\nfrom torch.utils.data import DataLoader, Subset, random_split\nimport esm\nfrom joblib import Parallel, delayed\nimport pickle\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T20:56:42.421581Z","iopub.execute_input":"2025-06-03T20:56:42.421833Z","iopub.status.idle":"2025-06-03T20:56:52.830310Z","shell.execute_reply.started":"2025-06-03T20:56:42.421806Z","shell.execute_reply":"2025-06-03T20:56:52.829545Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch_geometric/typing.py:86: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: /usr/local/lib/python3.11/dist-packages/torch_scatter/_version_cuda.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs\n  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n/usr/local/lib/python3.11/dist-packages/torch_geometric/typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /usr/local/lib/python3.11/dist-packages/torch_sparse/_version_cuda.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs\n  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"pIC50=np.load('/kaggle/input/drug-virus-features/pIC50.npy')\nwith open(\"/kaggle/input/drug-virus-features/drug_graphs.pkl\", \"rb\") as f:\n    drug_graphs = pickle.load(f)\nwith open(\"/kaggle/input/drug-virus-features/protein_graphs.pkl\", \"rb\") as f:\n    protein_graphs = pickle.load(f)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T20:56:52.831670Z","iopub.execute_input":"2025-06-03T20:56:52.832185Z","iopub.status.idle":"2025-06-03T20:56:56.840285Z","shell.execute_reply.started":"2025-06-03T20:56:52.832158Z","shell.execute_reply":"2025-06-03T20:56:56.839639Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"def drug_graph_to_data(drug_graph):\n    mol_size, nodes, edges, edges_type = drug_graph\n    x = torch.tensor(nodes, dtype=torch.float)  # [num_nodes, node_features]\n    \n    edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()  # [2, num_edges]\n    edge_attr = torch.tensor(edges_type, dtype=torch.float).unsqueeze(1)  # [num_edges, 1]\n    \n    data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n    return data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T20:56:56.841241Z","iopub.execute_input":"2025-06-03T20:56:56.841562Z","iopub.status.idle":"2025-06-03T20:56:56.846008Z","shell.execute_reply.started":"2025-06-03T20:56:56.841536Z","shell.execute_reply":"2025-06-03T20:56:56.845471Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def protein_graph_to_data(protein_graph):\n    node_features,edge_index,edge_attr = protein_graph\n    x = node_features\n    \n    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()  # [2, num_edges]\n    edge_attr = torch.tensor(edge_attr, dtype=torch.float).unsqueeze(1)  # [num_edges, 1]\n    \n    data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n    return data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T20:56:59.142398Z","iopub.execute_input":"2025-06-03T20:56:59.142947Z","iopub.status.idle":"2025-06-03T20:56:59.146968Z","shell.execute_reply.started":"2025-06-03T20:56:59.142925Z","shell.execute_reply":"2025-06-03T20:56:59.146330Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"class DrugProteinDataset(torch.utils.data.Dataset):\n    def __init__(self, protein_graphs, drug_graphs, pIC50_values):\n        self.protein_graphs = protein_graphs\n        self.drug_graphs = drug_graphs\n        self.pIC50_values = pIC50_values\n    \n    def __len__(self):\n        return len(self.pIC50_values)\n    \n    def __getitem__(self, idx):\n        protein_graphs = protein_graph_to_data(self.protein_graphs[idx])\n        drug_graph = drug_graph_to_data(self.drug_graphs[idx])\n        pIC50_value = torch.tensor(self.pIC50_values[idx], dtype=torch.float)\n        return protein_graphs, drug_graph, pIC50_value\n\ndef custom_collate(batch):\n    protein_graphs = ([item[0] for item in batch])  \n    drug_graphs = [item[1] for item in batch]                 # List of PyG Data objects\n    labels = torch.stack([item[2] for item in batch])         # [batch_size]\n\n    batch_protein_graphs = Batch.from_data_list(protein_graphs)     # Combine graphs into a single batched graph\n    batch_drug_graphs = Batch.from_data_list(drug_graphs)     # Combine graphs into a single batched graph\n\n    return batch_protein_graphs, batch_drug_graphs, labels\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T20:57:05.512216Z","iopub.execute_input":"2025-06-03T20:57:05.512901Z","iopub.status.idle":"2025-06-03T20:57:05.518829Z","shell.execute_reply.started":"2025-06-03T20:57:05.512876Z","shell.execute_reply":"2025-06-03T20:57:05.517988Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"class DrugTargetGNN(nn.Module):\n    def __init__(self, node_feature_dim=78, protein_feature_dim=20, hidden_dim=128):\n        super().__init__()\n        # GNN layers for drug graph\n        self.drugconv1 = GCNConv(node_feature_dim, node_feature_dim)\n        self.drugconv2 = GCNConv(node_feature_dim, node_feature_dim*2)\n        self.drugconv3 = GCNConv(node_feature_dim*2, node_feature_dim*4)\n        self.druglinear1 = nn.Linear(node_feature_dim*4, 1024)\n        self.druglinear2 = nn.Linear(1024, hidden_dim)\n\n        \n        #GNN layers for protein graph\n        self.proteinconv1 = GCNConv(protein_feature_dim, protein_feature_dim)\n        self.proteinconv2 = GCNConv(protein_feature_dim, protein_feature_dim*2)\n        self.proteinconv3 = GCNConv(protein_feature_dim*2, protein_feature_dim*4)\n        self.proteinlinear1 = nn.Linear(protein_feature_dim*4, 1024)\n        self.proteinlinear2 = nn.Linear(1024, hidden_dim)\n\n        \n        # Final layers for combined features\n        self.final_mlp = nn.Sequential(\n            nn.Linear(hidden_dim * 2, 1024),\n            nn.ReLU(),\n            \n            nn.Linear(1024, 512),\n            nn.ReLU(),\n            nn.Linear(512, 1)  # regression output for pIC50\n        )\n\n        \n    def forward(self, protein_graph, drug_graph):\n        # GNN on drug graph\n        x, edge_index,edge_attr = drug_graph.x, drug_graph.edge_index,drug_graph.edge_attr\n        p, edge_index_p,edge_attr_p = protein_graph.x, protein_graph.edge_index,protein_graph.edge_attr\n\n        x = F.relu(self.drugconv1(x, edge_index,edge_attr))\n        x = F.relu(self.drugconv2(x, edge_index,edge_attr))\n        x = F.relu(self.drugconv3(x, edge_index,edge_attr))\n        \n        x = global_mean_pool(x, drug_graph.batch)  # [batch_size, hidden_dim]\n        x = F.relu(self.druglinear1(x))\n        x = F.relu(self.druglinear2(x))\n\n\n        p = F.relu(self.proteinconv1(p, edge_index_p,edge_attr_p))\n        p = F.relu(self.proteinconv2(p, edge_index_p,edge_attr_p))\n        p = F.relu(self.proteinconv3(p, edge_index_p,edge_attr_p))\n        \n        p = global_mean_pool(p, protein_graph.batch)  # [batch_size, hidden_dim]\n        p = F.relu(self.proteinlinear1(p))\n        p = F.relu(self.proteinlinear2(p))\n\n\n\n        \n        \n        \n        # Combine embeddings\n        combined = torch.cat([x, p], dim=1)\n        out = self.final_mlp(combined)\n        return out.squeeze()  # [batch_size]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T20:57:11.476575Z","iopub.execute_input":"2025-06-03T20:57:11.477118Z","iopub.status.idle":"2025-06-03T20:57:11.485597Z","shell.execute_reply.started":"2025-06-03T20:57:11.477095Z","shell.execute_reply":"2025-06-03T20:57:11.484928Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"\ndataset = DrugProteinDataset(protein_graphs, drug_graphs, pIC50)\n\n# Set split sizes\ntotal_size = len(dataset)\ntrain_size = int(0.8 * total_size)\nval_size = int(0.1 * total_size)\ntest_size = total_size - train_size - val_size  # to avoid rounding issues\n\n# Split the dataset\ntrain_dataset, val_dataset, test_dataset = random_split(\n    dataset,\n    lengths=[train_size, val_size, test_size],\n    generator=torch.Generator().manual_seed(42)  # for reproducibility\n)\n\n\ntrain_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, collate_fn=custom_collate)\nval_loader = DataLoader(val_dataset, batch_size=128, shuffle=False, collate_fn=custom_collate)\ntest_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, collate_fn=custom_collate)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T20:57:13.467443Z","iopub.execute_input":"2025-06-03T20:57:13.467714Z","iopub.status.idle":"2025-06-03T20:57:13.476191Z","shell.execute_reply.started":"2025-06-03T20:57:13.467695Z","shell.execute_reply":"2025-06-03T20:57:13.475469Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = DrugTargetGNN().to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\ncriterion = nn.MSELoss()  # for regression\n\nmodel.train()\nfor epoch in range(50):\n    total_loss = 0\n    for protein_graph, drug_graph, values in train_loader:\n        protein_graph = protein_graph.to(device)\n        drug_graph = drug_graph.to(device)\n        values = values.to(device)\n\n        optimizer.zero_grad()\n        outputs = model(protein_graph, drug_graph)\n        loss = criterion(outputs, values)\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n\n    avg_loss = total_loss / len(train_loader)\n    print(f\"Epoch {epoch+1}, Loss: {avg_loss:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T20:57:17.095582Z","iopub.execute_input":"2025-06-03T20:57:17.096239Z","iopub.status.idle":"2025-06-03T21:13:10.692429Z","shell.execute_reply.started":"2025-06-03T20:57:17.096216Z","shell.execute_reply":"2025-06-03T21:13:10.691775Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_35/3637523408.py:3: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:254.)\n  x = torch.tensor(nodes, dtype=torch.float)  # [num_nodes, node_features]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1, Loss: 4.7635\nEpoch 2, Loss: 2.2944\nEpoch 3, Loss: 2.0917\nEpoch 4, Loss: 2.0167\nEpoch 5, Loss: 1.9404\nEpoch 6, Loss: 1.9829\nEpoch 7, Loss: 1.7829\nEpoch 8, Loss: 1.6932\nEpoch 9, Loss: 1.6988\nEpoch 10, Loss: 1.6053\nEpoch 11, Loss: 1.5533\nEpoch 12, Loss: 1.5234\nEpoch 13, Loss: 1.4157\nEpoch 14, Loss: 1.4064\nEpoch 15, Loss: 1.3745\nEpoch 16, Loss: 1.3210\nEpoch 17, Loss: 1.3319\nEpoch 18, Loss: 1.2608\nEpoch 19, Loss: 1.2303\nEpoch 20, Loss: 1.2052\nEpoch 21, Loss: 1.1593\nEpoch 22, Loss: 1.1671\nEpoch 23, Loss: 1.1506\nEpoch 24, Loss: 1.0995\nEpoch 25, Loss: 1.0544\nEpoch 26, Loss: 1.0481\nEpoch 27, Loss: 1.0454\nEpoch 28, Loss: 1.0050\nEpoch 29, Loss: 0.9707\nEpoch 30, Loss: 0.9632\nEpoch 31, Loss: 0.9230\nEpoch 32, Loss: 0.9145\nEpoch 33, Loss: 0.9036\nEpoch 34, Loss: 0.8997\nEpoch 35, Loss: 0.8917\nEpoch 36, Loss: 0.8464\nEpoch 37, Loss: 0.8321\nEpoch 38, Loss: 0.8214\nEpoch 39, Loss: 0.8034\nEpoch 40, Loss: 0.7752\nEpoch 41, Loss: 0.8045\nEpoch 42, Loss: 0.7705\nEpoch 43, Loss: 0.7653\nEpoch 44, Loss: 0.7283\nEpoch 45, Loss: 0.7338\nEpoch 46, Loss: 0.7097\nEpoch 47, Loss: 0.6847\nEpoch 48, Loss: 0.6986\nEpoch 49, Loss: 0.6935\nEpoch 50, Loss: 0.6692\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"\ndef evaluate(model, dataloader, device):\n    model.eval()\n    all_preds = []\n    all_labels = []\n\n    with torch.no_grad():\n        for protein_graph, drug_graphs, values in dataloader:\n            protein_graph = protein_graph.to(device)\n            drug_graphs = drug_graphs.to(device)\n            values = values.to(device)\n\n            outputs = model(protein_graph, drug_graphs)\n            all_preds.append(outputs.cpu())\n            all_labels.append(values.cpu())\n         \n    preds = torch.cat(all_preds).numpy()\n   \n    values = torch.cat(all_labels).numpy()\n\n    mse = mean_squared_error(values, preds)\n    rmse = mse ** 0.5\n    pearson_corr, _ = pearsonr(values, preds)\n\n    return {\n        \"MSE\": mse,\n        \"RMSE\": rmse,\n        \"Pearson\": pearson_corr\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T21:13:18.697381Z","iopub.execute_input":"2025-06-03T21:13:18.697938Z","iopub.status.idle":"2025-06-03T21:13:18.703506Z","shell.execute_reply.started":"2025-06-03T21:13:18.697916Z","shell.execute_reply":"2025-06-03T21:13:18.702545Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\nval_metrics = evaluate(model, val_loader, device)\nprint(\"Validation Metrics:\", val_metrics)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T21:13:19.492161Z","iopub.execute_input":"2025-06-03T21:13:19.492970Z","iopub.status.idle":"2025-06-03T21:13:21.807303Z","shell.execute_reply.started":"2025-06-03T21:13:19.492938Z","shell.execute_reply":"2025-06-03T21:13:21.806479Z"}},"outputs":[{"name":"stdout","text":"Validation Metrics: {'MSE': 0.8421124, 'RMSE': 0.9176668360518652, 'Pearson': 0.83900267}\n","output_type":"stream"}],"execution_count":14}]}