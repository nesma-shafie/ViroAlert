{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12034111,"sourceType":"datasetVersion","datasetId":7572023},{"sourceId":12046935,"sourceType":"datasetVersion","datasetId":7581212}],"dockerImageVersionId":31042,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !pip install biopython\n!pip install --upgrade --no-cache-dir biopython\n!pip install rdkit-pypi\n!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-2.2.0+cu118.html\n!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-2.2.0+cu118.html\n!pip install -q torch-geometric\n!pip install fair-esm\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T19:53:22.197039Z","iopub.execute_input":"2025-06-03T19:53:22.197256Z","iopub.status.idle":"2025-06-03T19:53:46.607759Z","shell.execute_reply.started":"2025-06-03T19:53:22.197239Z","shell.execute_reply":"2025-06-03T19:53:46.606744Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom tqdm import tqdm\nimport torch\nfrom torch_geometric.data import Data\nfrom torch_geometric.data import Batch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch_geometric.nn import GCNConv, global_mean_pool\nfrom sklearn.metrics import mean_squared_error\nfrom scipy.stats import pearsonr\nimport pickle\nfrom torch.utils.data import DataLoader, Subset, random_split\nimport esm\nfrom joblib import Parallel, delayed\nimport pickle\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T19:53:46.611524Z","iopub.execute_input":"2025-06-03T19:53:46.611818Z","iopub.status.idle":"2025-06-03T19:53:56.222842Z","shell.execute_reply.started":"2025-06-03T19:53:46.611794Z","shell.execute_reply":"2025-06-03T19:53:56.222311Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pIC50=np.load('/kaggle/input/drug-virus-features/pIC50.npy')\nwith open(\"/kaggle/input/drug-virus-features/drug_graphs.pkl\", \"rb\") as f:\n    drug_graphs = pickle.load(f)\nwith open(\"/kaggle/input/drug-virus-features/protein_graphs.pkl\", \"rb\") as f:\n    protein_graphs = pickle.load(f)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T19:54:52.637834Z","iopub.execute_input":"2025-06-03T19:54:52.638460Z","iopub.status.idle":"2025-06-03T19:54:56.918456Z","shell.execute_reply.started":"2025-06-03T19:54:52.638435Z","shell.execute_reply":"2025-06-03T19:54:56.917638Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def drug_graph_to_data(drug_graph):\n    mol_size, nodes, edges, edges_type = drug_graph\n    x = torch.tensor(nodes, dtype=torch.float)  # [num_nodes, node_features]\n    \n    edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()  # [2, num_edges]\n    edge_attr = torch.tensor(edges_type, dtype=torch.float).unsqueeze(1)  # [num_edges, 1]\n    \n    data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n    return data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T19:55:21.730498Z","iopub.execute_input":"2025-06-03T19:55:21.731285Z","iopub.status.idle":"2025-06-03T19:55:21.735670Z","shell.execute_reply.started":"2025-06-03T19:55:21.731258Z","shell.execute_reply":"2025-06-03T19:55:21.734924Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def protein_graph_to_data(protein_graph):\n    node_features,edge_index,edge_attr = protein_graph\n    x = node_features\n    \n    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()  # [2, num_edges]\n    edge_attr = torch.tensor(edge_attr, dtype=torch.float).unsqueeze(1)  # [num_edges, 1]\n    \n    data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n    return data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T19:55:23.476405Z","iopub.execute_input":"2025-06-03T19:55:23.476969Z","iopub.status.idle":"2025-06-03T19:55:23.481876Z","shell.execute_reply.started":"2025-06-03T19:55:23.476942Z","shell.execute_reply":"2025-06-03T19:55:23.481085Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class DrugProteinDataset(torch.utils.data.Dataset):\n    def __init__(self, protein_graphs, drug_graphs, pIC50_values):\n        self.protein_graphs = protein_graphs\n        self.drug_graphs = drug_graphs\n        self.pIC50_values = pIC50_values\n    \n    def __len__(self):\n        return len(self.pIC50_values)\n    \n    def __getitem__(self, idx):\n        protein_graphs = protein_graph_to_data(self.protein_graphs[idx])\n        drug_graph = drug_graph_to_data(self.drug_graphs[idx])\n        pIC50_value = torch.tensor(self.pIC50_values[idx], dtype=torch.float)\n        return protein_graphs, drug_graph, pIC50_value\n\ndef custom_collate(batch):\n    protein_graphs = ([item[0] for item in batch])  \n    drug_graphs = [item[1] for item in batch]                 # List of PyG Data objects\n    labels = torch.stack([item[2] for item in batch])         # [batch_size]\n\n    batch_protein_graphs = Batch.from_data_list(protein_graphs)     # Combine graphs into a single batched graph\n    batch_drug_graphs = Batch.from_data_list(drug_graphs)     # Combine graphs into a single batched graph\n\n    return batch_protein_graphs, batch_drug_graphs, labels\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T19:55:27.204505Z","iopub.execute_input":"2025-06-03T19:55:27.205066Z","iopub.status.idle":"2025-06-03T19:55:27.210739Z","shell.execute_reply.started":"2025-06-03T19:55:27.205043Z","shell.execute_reply":"2025-06-03T19:55:27.210236Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class DrugTargetGNN(nn.Module):\n    def __init__(self, node_feature_dim=78, protein_feature_dim=20, hidden_dim=128):\n        super().__init__()\n        # GNN layers for drug graph\n        self.drugconv1 = GCNConv(node_feature_dim, node_feature_dim)\n        self.drugconv2 = GCNConv(node_feature_dim, node_feature_dim*2)\n        self.drugconv3 = GCNConv(node_feature_dim*2, node_feature_dim*4)\n        self.druglinear1 = nn.Linear(node_feature_dim*4, 1024)\n        self.druglinear2 = nn.Linear(1024, hidden_dim)\n\n        \n        #GNN layers for protein graph\n        self.proteinconv1 = GCNConv(protein_feature_dim, protein_feature_dim)\n        self.proteinconv2 = GCNConv(protein_feature_dim, protein_feature_dim*2)\n        self.proteinconv3 = GCNConv(protein_feature_dim*2, protein_feature_dim*4)\n        self.proteinlinear1 = nn.Linear(protein_feature_dim*4, 1024)\n        self.proteinlinear2 = nn.Linear(1024, hidden_dim)\n\n        \n        # Final layers for combined features\n        self.final_mlp = nn.Sequential(\n            nn.Linear(hidden_dim * 2, 1024),\n            nn.ReLU(),\n            \n            nn.Linear(1024, 512),\n            nn.ReLU(),\n            nn.Linear(512, 1)  # regression output for pIC50\n        )\n\n        \n    def forward(self, protein_graph, drug_graph):\n        # GNN on drug graph\n        x, edge_index,edge_attr = drug_graph.x, drug_graph.edge_index,drug_graph.edge_attr\n        p, edge_index_p,edge_attr_p = protein_graph.x, protein_graph.edge_index,protein_graph.edge_attr\n\n        x = F.relu(self.drugconv1(x, edge_index,edge_attr))\n        x = F.relu(self.drugconv2(x, edge_index,edge_attr))\n        x = F.relu(self.drugconv3(x, edge_index,edge_attr))\n        \n        x = global_mean_pool(x, drug_graph.batch)  # [batch_size, hidden_dim]\n        x = F.relu(self.druglinear1(x))\n        x = F.relu(self.druglinear2(x))\n\n\n        p = F.relu(self.proteinconv1(p, edge_index_p,edge_attr_p))\n        p = F.relu(self.proteinconv2(p, edge_index_p,edge_attr_p))\n        p = F.relu(self.proteinconv3(p, edge_index_p,edge_attr_p))\n        \n        p = global_mean_pool(p, protein_graph.batch)  # [batch_size, hidden_dim]\n        p = F.relu(self.proteinlinear1(p))\n        p = F.relu(self.proteinlinear2(p))\n\n\n\n        \n        \n        \n        # Combine embeddings\n        combined = torch.cat([x, p], dim=1)\n        out = self.final_mlp(combined)\n        return out.squeeze()  # [batch_size]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T20:09:05.084585Z","iopub.execute_input":"2025-06-03T20:09:05.084869Z","iopub.status.idle":"2025-06-03T20:09:05.093601Z","shell.execute_reply.started":"2025-06-03T20:09:05.084847Z","shell.execute_reply":"2025-06-03T20:09:05.092950Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ndataset = DrugProteinDataset(protein_graphs, drug_graphs, pIC50)\n\n# Set split sizes\ntotal_size = len(dataset)\ntrain_size = int(0.8 * total_size)\nval_size = int(0.1 * total_size)\ntest_size = total_size - train_size - val_size  # to avoid rounding issues\n\n# Split the dataset\ntrain_dataset, val_dataset, test_dataset = random_split(\n    dataset,\n    lengths=[train_size, val_size, test_size],\n    generator=torch.Generator().manual_seed(42)  # for reproducibility\n)\n\n\ntrain_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, collate_fn=custom_collate)\nval_loader = DataLoader(val_dataset, batch_size=128, shuffle=False, collate_fn=custom_collate)\ntest_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, collate_fn=custom_collate)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T19:55:34.750127Z","iopub.execute_input":"2025-06-03T19:55:34.750871Z","iopub.status.idle":"2025-06-03T19:55:34.758501Z","shell.execute_reply.started":"2025-06-03T19:55:34.750847Z","shell.execute_reply":"2025-06-03T19:55:34.757887Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = DrugTargetGNN().to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\ncriterion = nn.MSELoss()  # for regression\n\nmodel.train()\nfor epoch in range(50):\n    total_loss = 0\n    for protein_graph, drug_graph, values in train_loader:\n        protein_graph = protein_graph.to(device)\n        drug_graph = drug_graph.to(device)\n        values = values.to(device)\n\n        optimizer.zero_grad()\n        outputs = model(protein_graph, drug_graph)\n        loss = criterion(outputs, values)\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n\n    avg_loss = total_loss / len(train_loader)\n    print(f\"Epoch {epoch+1}, Loss: {avg_loss:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T20:15:51.693921Z","iopub.execute_input":"2025-06-03T20:15:51.694471Z","iopub.status.idle":"2025-06-03T20:31:21.214592Z","shell.execute_reply.started":"2025-06-03T20:15:51.694445Z","shell.execute_reply":"2025-06-03T20:31:21.213950Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ndef evaluate(model, dataloader, device):\n    model.eval()\n    all_preds = []\n    all_labels = []\n\n    with torch.no_grad():\n        for protein_graph, drug_graphs, values in dataloader:\n            protein_graph = protein_graph.to(device)\n            drug_graphs = drug_graphs.to(device)\n            values = values.to(device)\n\n            outputs = model(protein_graph, drug_graphs)\n            all_preds.append(outputs.cpu())\n            all_labels.append(values.cpu())\n         \n    preds = torch.cat(all_preds).numpy()\n   \n    values = torch.cat(all_labels).numpy()\n\n    mse = mean_squared_error(values, preds)\n    rmse = mse ** 0.5\n    pearson_corr, _ = pearsonr(values, preds)\n\n    return {\n        \"MSE\": mse,\n        \"RMSE\": rmse,\n        \"Pearson\": pearson_corr\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T20:03:10.363107Z","iopub.execute_input":"2025-06-03T20:03:10.363721Z","iopub.status.idle":"2025-06-03T20:03:10.369367Z","shell.execute_reply.started":"2025-06-03T20:03:10.363697Z","shell.execute_reply":"2025-06-03T20:03:10.368615Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\nval_metrics = evaluate(model, val_loader, device)\nprint(\"Validation Metrics:\", val_metrics)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T20:31:26.145717Z","iopub.execute_input":"2025-06-03T20:31:26.146443Z","iopub.status.idle":"2025-06-03T20:31:28.393598Z","shell.execute_reply.started":"2025-06-03T20:31:26.146408Z","shell.execute_reply":"2025-06-03T20:31:28.392975Z"}},"outputs":[],"execution_count":null}]}