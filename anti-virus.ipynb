{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12034111,"sourceType":"datasetVersion","datasetId":7572023},{"sourceId":12046935,"sourceType":"datasetVersion","datasetId":7581212}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !pip install biopython\n!pip install --upgrade --no-cache-dir biopython\n!pip install rdkit-pypi\n!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-2.2.0+cu118.html\n!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-2.2.0+cu118.html\n!pip install -q torch-geometric","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T12:02:17.947681Z","iopub.execute_input":"2025-06-03T12:02:17.947997Z","iopub.status.idle":"2025-06-03T12:02:42.277179Z","shell.execute_reply.started":"2025-06-03T12:02:17.947966Z","shell.execute_reply":"2025-06-03T12:02:42.276124Z"}},"outputs":[{"name":"stdout","text":"Collecting biopython\n  Downloading biopython-1.85-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from biopython) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->biopython) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->biopython) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->biopython) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->biopython) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->biopython) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->biopython) (2.4.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->biopython) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->biopython) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->biopython) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->biopython) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->biopython) (2024.2.0)\nDownloading biopython-1.85-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: biopython\nSuccessfully installed biopython-1.85\nCollecting rdkit-pypi\n  Downloading rdkit_pypi-2022.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rdkit-pypi) (1.26.4)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit-pypi) (11.0.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->rdkit-pypi) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->rdkit-pypi) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->rdkit-pypi) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->rdkit-pypi) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->rdkit-pypi) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->rdkit-pypi) (2.4.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->rdkit-pypi) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->rdkit-pypi) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->rdkit-pypi) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->rdkit-pypi) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->rdkit-pypi) (2024.2.0)\nDownloading rdkit_pypi-2022.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.4/29.4 MB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: rdkit-pypi\nSuccessfully installed rdkit-pypi-2022.9.5\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import numpy as np\nfrom collections import Counter\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom Bio.Align import substitution_matrices\nfrom sklearn.cluster import KMeans\nfrom scipy.spatial.distance import squareform\nfrom scipy.cluster.hierarchy import linkage, fcluster\nfrom rdkit import Chem\nfrom rdkit.Chem import AllChem\nimport numpy as np\nfrom tqdm import tqdm\nfrom joblib import Parallel, delayed\nimport itertools\nimport torch\nfrom torch_geometric.data import Data\nfrom torch.utils.data import DataLoader\nfrom torch_geometric.data import Batch\nimport torch.nn as nn\nfrom sklearn.decomposition import PCA\n\nimport torch.nn.functional as F\nfrom torch_geometric.nn import GCNConv, global_mean_pool\nfrom torch.utils.data import random_split, DataLoader\nfrom sklearn.metrics import mean_squared_error\nfrom scipy.stats import pearsonr\nimport torch\nimport pickle\nfrom torch.utils.data import DataLoader, Subset, random_split\nimport pandas as pd\n\n\nblosum62 = substitution_matrices.load('BLOSUM62')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T14:46:46.835947Z","iopub.execute_input":"2025-06-03T14:46:46.836227Z","iopub.status.idle":"2025-06-03T14:46:46.844502Z","shell.execute_reply.started":"2025-06-03T14:46:46.836206Z","shell.execute_reply":"2025-06-03T14:46:46.843612Z"}},"outputs":[],"execution_count":111},{"cell_type":"code","source":"protein_features=np.load('/kaggle/input/drug-virus-features/protein_features.npy')\npIC50=np.load('/kaggle/input/drug-virus-features/pIC50.npy')\nwith open(\"/kaggle/input/drug-virus-features/drug_graphs.pkl\", \"rb\") as f:\n    drug_graphs = pickle.load(f)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T14:45:46.676687Z","iopub.execute_input":"2025-06-03T14:45:46.677037Z","iopub.status.idle":"2025-06-03T14:45:49.509524Z","shell.execute_reply.started":"2025-06-03T14:45:46.677010Z","shell.execute_reply":"2025-06-03T14:45:49.508858Z"}},"outputs":[],"execution_count":108},{"cell_type":"code","source":"total_size = len(protein_features)\ntrain_size = int(0.7 * total_size)\nval_size = int(0.15 * total_size)\ntest_size = total_size - train_size - val_size\n\nall_indices = list(range(total_size))\ntrain_indices, val_indices, test_indices = random_split(\n    all_indices, [train_size, val_size, test_size],\n    generator=torch.Generator().manual_seed(42)\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T14:45:49.510575Z","iopub.execute_input":"2025-06-03T14:45:49.510822Z","iopub.status.idle":"2025-06-03T14:45:49.516549Z","shell.execute_reply.started":"2025-06-03T14:45:49.510802Z","shell.execute_reply":"2025-06-03T14:45:49.515850Z"}},"outputs":[],"execution_count":109},{"cell_type":"code","source":"train_protein = protein_features[train_indices] \npca = PCA(n_components=50)\npca.fit(train_protein)\n\n# Step 3: Transform all sets\nprotein_pca = pca.transform(protein_features)\nprotein_pca = torch.tensor(protein_pca, dtype=torch.float32)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T14:58:49.358220Z","iopub.execute_input":"2025-06-03T14:58:49.358550Z","iopub.status.idle":"2025-06-03T14:58:49.944900Z","shell.execute_reply.started":"2025-06-03T14:58:49.358525Z","shell.execute_reply":"2025-06-03T14:58:49.943981Z"}},"outputs":[],"execution_count":131},{"cell_type":"code","source":"def drug_graph_to_data(drug_graph):\n    mol_size, nodes, edges, edges_type = drug_graph\n    x = torch.tensor(nodes, dtype=torch.float)  # [num_nodes, node_features]\n    \n    edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()  # [2, num_edges]\n    edge_attr = torch.tensor(edges_type, dtype=torch.float).unsqueeze(1)  # [num_edges, 1]\n    \n    data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n    return data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T14:58:50.038912Z","iopub.execute_input":"2025-06-03T14:58:50.039186Z","iopub.status.idle":"2025-06-03T14:58:50.043673Z","shell.execute_reply.started":"2025-06-03T14:58:50.039166Z","shell.execute_reply":"2025-06-03T14:58:50.042754Z"}},"outputs":[],"execution_count":132},{"cell_type":"code","source":"class DrugProteinDataset(torch.utils.data.Dataset):\n    def __init__(self, protein_features, drug_graphs, pIC50_values):\n        self.protein_features = protein_features\n        self.drug_graphs = drug_graphs\n        self.pIC50_values = pIC50_values\n    \n    def __len__(self):\n        return len(self.pIC50_values)\n    \n    def __getitem__(self, idx):\n        protein_feature = torch.tensor(self.protein_features[idx], dtype=torch.float)\n        drug_graph = drug_graph_to_data(self.drug_graphs[idx])\n        pIC50_value = torch.tensor(self.pIC50_values[idx], dtype=torch.float)\n        return protein_feature, drug_graph, pIC50_value\n\ndef custom_collate(batch):\n    protein_feats = torch.stack([item[0] for item in batch])  # [batch_size, protein_feature_dim]\n    drug_graphs = [item[1] for item in batch]                 # List of PyG Data objects\n    labels = torch.stack([item[2] for item in batch])         # [batch_size]\n\n    batch_drug_graphs = Batch.from_data_list(drug_graphs)     # Combine graphs into a single batched graph\n\n    return protein_feats, batch_drug_graphs, labels\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T14:58:50.675923Z","iopub.execute_input":"2025-06-03T14:58:50.676217Z","iopub.status.idle":"2025-06-03T14:58:50.681952Z","shell.execute_reply.started":"2025-06-03T14:58:50.676194Z","shell.execute_reply":"2025-06-03T14:58:50.681038Z"}},"outputs":[],"execution_count":133},{"cell_type":"code","source":"class DrugTargetGNN(nn.Module):\n    def __init__(self, node_feature_dim=78, protein_feature_dim=50, hidden_dim=128):\n        super().__init__()\n        # GNN layers for drug graph\n        self.conv1 = GCNConv(node_feature_dim, node_feature_dim)\n        self.conv2 = GCNConv(node_feature_dim, node_feature_dim*2)\n        self.conv3 = GCNConv(node_feature_dim*2, node_feature_dim*4)\n\n        \n        self.lineargraph = nn.Linear(node_feature_dim*4, hidden_dim)\n        \n        # MLP for protein features\n        self.protein_mlp = nn.Sequential(\n            nn.Linear(protein_feature_dim, protein_feature_dim*2),\n            nn.ReLU(),\n            nn.Linear(protein_feature_dim*2, protein_feature_dim*4),\n            nn.ReLU(),\n            nn.Linear(protein_feature_dim*4, hidden_dim)\n            \n        )\n        \n        # Final layers for combined features\n        self.final_mlp = nn.Sequential(\n            nn.Linear(hidden_dim * 2, hidden_dim),\n            nn.ReLU(),\n            \n            nn.Linear(hidden_dim, hidden_dim//2),\n            nn.ReLU(),\n            nn.Linear(hidden_dim//2, 1)  # regression output for pIC50\n        )\n\n        \n    def forward(self, protein_feat, drug_graph):\n        # GNN on drug graph\n        x, edge_index,edge_attr = drug_graph.x, drug_graph.edge_index,drug_graph.edge_attr\n        x = F.relu(self.conv1(x, edge_index,edge_attr))\n        x = F.relu(self.conv2(x, edge_index,edge_attr))\n        x = F.relu(self.conv3(x, edge_index,edge_attr))\n        \n        x = global_mean_pool(x, drug_graph.batch)  # [batch_size, hidden_dim]\n        x = F.relu(self.lineargraph(x))\n\n        \n        # Protein feature embedding\n        p = self.protein_mlp(protein_feat)  # [batch_size, hidden_dim]\n        \n        # Combine embeddings\n        combined = torch.cat([x, p], dim=1)\n        out = self.final_mlp(combined)\n        return out.squeeze()  # [batch_size]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T14:59:25.450834Z","iopub.execute_input":"2025-06-03T14:59:25.451163Z","iopub.status.idle":"2025-06-03T14:59:25.458718Z","shell.execute_reply.started":"2025-06-03T14:59:25.451140Z","shell.execute_reply":"2025-06-03T14:59:25.457747Z"}},"outputs":[],"execution_count":138},{"cell_type":"code","source":"\ndataset = DrugProteinDataset(protein_pca, drug_graphs, pIC50)\n\ntrain_dataset = Subset(dataset, train_indices)\nval_dataset = Subset(dataset, val_indices)\ntest_dataset = Subset(dataset, test_indices)\n\n\ntrain_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, collate_fn=custom_collate)\nval_loader = DataLoader(val_dataset, batch_size=128, shuffle=False, collate_fn=custom_collate)\ntest_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, collate_fn=custom_collate)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T14:58:51.935487Z","iopub.execute_input":"2025-06-03T14:58:51.935820Z","iopub.status.idle":"2025-06-03T14:58:51.940456Z","shell.execute_reply.started":"2025-06-03T14:58:51.935789Z","shell.execute_reply":"2025-06-03T14:58:51.939725Z"}},"outputs":[],"execution_count":135},{"cell_type":"code","source":"# dataset = DrugProteinDataset(protein_features, drug_graphs, pIC50)\n\n# # Step 1: Load the original CSV and get top 10 virus indices\n# df = pd.read_csv('/kaggle/input/virus-drug/virus_drug_interactions.csv')\n# top_3_viruses = df['Virus_Organism'].value_counts().head(3).index\n# top_3_indices = df[df['Virus_Organism'].isin(top_3_viruses)].index.tolist()\n\n# # Step 2: Get remaining indices\n# all_indices = set(range(len(df)))\n# remaining_indices = list(all_indices - set(top_3_indices))\n\n# # Step 3: Split remaining into val and test (50/50)\n# remaining_size = len(remaining_indices)\n# val_size = remaining_size // 2\n# test_size = remaining_size - val_size  # ensures no rounding errors\n\n# val_indices, test_indices = random_split(\n#     remaining_indices,\n#     [val_size, test_size],\n#     generator=torch.Generator().manual_seed(42)\n# )\n\n# # Step 4: Build subsets\n# train_dataset = Subset(dataset, top_10_indices)\n# val_dataset = Subset(dataset, val_indices)\n# test_dataset = Subset(dataset, test_indices)\n\n# # Step 5: Build DataLoaders\n# train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, collate_fn=custom_collate)\n# val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False, collate_fn=custom_collate)\n# test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, collate_fn=custom_collate)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T14:58:58.774467Z","iopub.execute_input":"2025-06-03T14:58:58.774808Z","iopub.status.idle":"2025-06-03T14:58:58.778565Z","shell.execute_reply.started":"2025-06-03T14:58:58.774780Z","shell.execute_reply":"2025-06-03T14:58:58.777645Z"}},"outputs":[],"execution_count":136},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = DrugTargetGNN().to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\ncriterion = nn.MSELoss()  # for regression\n\nmodel.train()\nfor epoch in range(20):\n    total_loss = 0\n    for protein_feat, drug_graph, values in train_loader:\n        protein_feat = protein_feat.to(device)\n        drug_graph = drug_graph.to(device)\n        values = values.to(device)\n\n        optimizer.zero_grad()\n        outputs = model(protein_feat, drug_graph)\n        loss = criterion(outputs, values)\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n\n    avg_loss = total_loss / len(train_loader)\n    print(f\"Epoch {epoch+1}, Loss: {avg_loss:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T14:59:29.150541Z","iopub.execute_input":"2025-06-03T14:59:29.150853Z","iopub.status.idle":"2025-06-03T15:03:34.888597Z","shell.execute_reply.started":"2025-06-03T14:59:29.150827Z","shell.execute_reply":"2025-06-03T15:03:34.887727Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-133-a969ade95676>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  protein_feature = torch.tensor(self.protein_features[idx], dtype=torch.float)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1, Loss: 5.4441\nEpoch 2, Loss: 2.1307\nEpoch 3, Loss: 2.0799\nEpoch 4, Loss: 1.9705\nEpoch 5, Loss: 1.9090\nEpoch 6, Loss: 1.8542\nEpoch 7, Loss: 1.9021\nEpoch 8, Loss: 1.8190\nEpoch 9, Loss: 1.8067\nEpoch 10, Loss: 1.7928\nEpoch 11, Loss: 1.7419\nEpoch 12, Loss: 1.7636\nEpoch 13, Loss: 1.7040\nEpoch 14, Loss: 1.6731\nEpoch 15, Loss: 1.6427\nEpoch 16, Loss: 1.6261\nEpoch 17, Loss: 1.6326\nEpoch 18, Loss: 1.5836\nEpoch 19, Loss: 1.5605\nEpoch 20, Loss: 1.5395\n","output_type":"stream"}],"execution_count":139},{"cell_type":"code","source":"\ndef evaluate(model, dataloader, device):\n    model.eval()\n    all_preds = []\n    all_labels = []\n\n    with torch.no_grad():\n        for protein_feats, drug_graphs, values in dataloader:\n            protein_feats = protein_feats.to(device)\n            drug_graphs = drug_graphs.to(device)\n            values = values.to(device)\n\n            outputs = model(protein_feats, drug_graphs)\n            all_preds.append(outputs.cpu())\n            all_labels.append(values.cpu())\n         \n    preds = torch.cat(all_preds).numpy()\n   \n    values = torch.cat(all_labels).numpy()\n\n    mse = mean_squared_error(values, preds)\n    rmse = mse ** 0.5\n    pearson_corr, _ = pearsonr(values, preds)\n\n    return {\n        \"MSE\": mse,\n        \"RMSE\": rmse,\n        \"Pearson\": pearson_corr\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T14:00:58.671074Z","iopub.execute_input":"2025-06-03T14:00:58.671370Z","iopub.status.idle":"2025-06-03T14:00:58.676776Z","shell.execute_reply.started":"2025-06-03T14:00:58.671349Z","shell.execute_reply":"2025-06-03T14:00:58.675903Z"}},"outputs":[],"execution_count":86},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\nval_metrics = evaluate(model, val_loader, device)\nprint(\"Validation Metrics:\", val_metrics)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T15:03:34.889808Z","iopub.execute_input":"2025-06-03T15:03:34.890073Z","iopub.status.idle":"2025-06-03T15:03:37.431521Z","shell.execute_reply.started":"2025-06-03T15:03:34.890051Z","shell.execute_reply":"2025-06-03T15:03:37.430630Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-133-a969ade95676>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  protein_feature = torch.tensor(self.protein_features[idx], dtype=torch.float)\n","output_type":"stream"},{"name":"stdout","text":"Validation Metrics: {'MSE': 1.536095, 'RMSE': 1.2393930059328284, 'Pearson': 0.7020078713583493}\n","output_type":"stream"}],"execution_count":140},{"cell_type":"code","source":"import pandas as pd\n\n# Load your dataset\ndf = pd.read_csv('/kaggle/input/virus-drug/virus_drug_interactions.csv')\n\n# Count the number of occurrences for each unique Virus_Organism\nvirus_counts = df['Virus_Organism'].value_counts()\n\n# Get the top 10 most frequent Virus_Organisms\ntop_10_viruses = virus_counts.head(3).index\n\n# Get the indices of these top 10 viruses in the original DataFrame\ntop_10_indices = df[df['Virus_Organism'].isin(top_10_viruses)].index.tolist()\n\n# Print the indices\nprint(\"Indices of top 10 Virus_Organisms in the original file:\")\nprint(len(top_10_indices))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T12:29:59.923434Z","iopub.execute_input":"2025-06-03T12:29:59.923764Z","iopub.status.idle":"2025-06-03T12:30:00.040926Z","shell.execute_reply.started":"2025-06-03T12:29:59.923739Z","shell.execute_reply":"2025-06-03T12:30:00.039977Z"}},"outputs":[{"name":"stdout","text":"Indices of top 10 Virus_Organisms in the original file:\n13532\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"print(len(top_3_indices))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T12:41:05.674938Z","iopub.execute_input":"2025-06-03T12:41:05.675247Z","iopub.status.idle":"2025-06-03T12:41:05.679546Z","shell.execute_reply.started":"2025-06-03T12:41:05.675224Z","shell.execute_reply":"2025-06-03T12:41:05.678773Z"}},"outputs":[{"name":"stdout","text":"13532\n","output_type":"stream"}],"execution_count":46},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}