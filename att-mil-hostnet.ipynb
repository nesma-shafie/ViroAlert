{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12059190,"sourceType":"datasetVersion","datasetId":6981441}],"dockerImageVersionId":30920,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !pip install --no-cache-dir gensim\n# import gensim\n# print(gensim.__version__)\n# !pip install faiss-cpu\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T18:19:12.922457Z","iopub.execute_input":"2025-06-05T18:19:12.922716Z","iopub.status.idle":"2025-06-05T18:19:12.926463Z","shell.execute_reply.started":"2025-06-05T18:19:12.922693Z","shell.execute_reply":"2025-06-05T18:19:12.925518Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom __future__ import print_function\nimport argparse\nimport numpy as np\nimport torch.optim as optim\nimport torch.utils.data as data_utils\nfrom torch.autograd import Variable\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import Subset\nfrom collections import Counter\nfrom collections import defaultdict\nfrom tqdm import tqdm\nfrom gensim.models import Word2Vec,KeyedVectors\nfrom torch.nn import TransformerEncoder, TransformerEncoderLayer\nimport os\nimport pandas as pd\nfrom itertools import chain\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import classification_report, roc_curve, auc\nfrom sklearn.preprocessing import label_binarize\n\n\ntorch.manual_seed(42)\nnp.random.seed(42)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Auto-detect GPU\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T18:19:12.928037Z","iopub.execute_input":"2025-06-05T18:19:12.928375Z","iopub.status.idle":"2025-06-05T18:19:39.476456Z","shell.execute_reply.started":"2025-06-05T18:19:12.928327Z","shell.execute_reply":"2025-06-05T18:19:39.475765Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"\ndef read_data_from_file(filename):\n    file_path = os.path.abspath(filename)\n\n    # Read CSV file\n    df = pd.read_csv(file_path)\n\n    # Rename columns\n    df.columns = [\"ID\", \"Sequence\"]\n    \n\n    # Drop rows where Sequence is not a string or is missing\n    df = df[df[\"Sequence\"].apply(lambda x: isinstance(x, str))].copy()\n    df = df[df[\"Sequence\"].apply(lambda x: len(x) >= 202 if isinstance(x, str) else False)].copy()\n\n    # Extract fields\n    df[\"Virus_ID\"] = df[\"ID\"].apply(lambda x: \"\".join(x.split(\"|\")[1:]) if \"|\" in x else \"\")\n    df[\"Seq_ID\"] = df[\"ID\"].apply(lambda x: x.split(\"|\")[0] if \"|\" in x else \"\")\n    df[\"Class\"] = df[\"ID\"].apply(lambda x: x.split(\"|\")[-1] if \"|\" in x else \"\")\n    df[\"Length\"] = df[\"Sequence\"].apply(len)\n\n    return df[[\"Sequence\", \"Virus_ID\", \"Seq_ID\", \"Class\", \"Length\"]]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T18:19:39.477603Z","iopub.execute_input":"2025-06-05T18:19:39.478102Z","iopub.status.idle":"2025-06-05T18:19:39.484183Z","shell.execute_reply.started":"2025-06-05T18:19:39.478078Z","shell.execute_reply":"2025-06-05T18:19:39.483390Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"def ASW(sequence, l_sub, n):\n    \"\"\"\n        sequence (str): The original viral sequence.\n        l_sub (int): The length of each subsequence.\n        n (int): The number of subsequences to generate.\n    \"\"\"\n    l = len(sequence)\n    \n \n    if n > 1:\n        l_stride = (l - l_sub) // (n - 1)\n    else:\n        l_stride = 1  \n    \n    subsequences = []\n\n \n    for i in range(0, min(n * l_stride, l - l_sub + 1), l_stride):\n        subsequences.append(sequence[i:i + l_sub])\n    \n    return subsequences\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T18:19:39.485145Z","iopub.execute_input":"2025-06-05T18:19:39.485471Z","iopub.status.idle":"2025-06-05T18:19:39.505794Z","shell.execute_reply.started":"2025-06-05T18:19:39.485440Z","shell.execute_reply":"2025-06-05T18:19:39.504948Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# 0->human  1-> animals\nclass GatedAttention(nn.Module):\n    def __init__(self,N_HEAD,ENCODER_N_LAYERS,EMBEDDING_SIZE,INTERMIDIATE_DIM):\n        super(GatedAttention, self).__init__()\n        self.M = EMBEDDING_SIZE\n        self.L = INTERMIDIATE_DIM\n        self.ENCODER_N_LAYERS=ENCODER_N_LAYERS\n        self.ATTENTION_BRANCHES = 1\n        self.N_HEAD=N_HEAD\n\n        # embedding \n        self.encoder_layer = TransformerEncoderLayer(d_model=self.M, nhead=self.N_HEAD)\n        self.transformer_encoder = TransformerEncoder(self.encoder_layer, num_layers=self.ENCODER_N_LAYERS)\n        \n        # instance level \n        self.attention_V_1 = nn.Sequential(\n            nn.Linear(self.M, self.L), # matrix V\n            nn.Tanh()\n        )\n\n        self.attention_U_1 = nn.Sequential(\n            nn.Linear(self.M, self.L), # matrix U\n            nn.Sigmoid()\n        )\n\n        self.attention_w_1 = nn.Linear(self.L, self.ATTENTION_BRANCHES) # matrix w (or vector w if self.ATTENTION_BRANCHES==1)\n\n\n        # bag level \n        self.attention_V_2 = nn.Sequential(\n            nn.Linear(self.M, self.L), # matrix V\n            nn.Tanh()\n        )\n\n        self.attention_U_2 = nn.Sequential(\n            nn.Linear(self.M, self.L), # matrix U\n            nn.Sigmoid()\n        )\n\n        self.attention_w_2 = nn.Linear(self.L, self.ATTENTION_BRANCHES) # matrix w (or vector w if self.ATTENTION_BRANCHES==1)\n\n\n        \n        # classifier\n        self.classifier = nn.Sequential(\n            nn.Conv1d(in_channels=self.ATTENTION_BRANCHES, out_channels=128, kernel_size=4, padding='same'),\n            nn.BatchNorm1d(128),\n            nn.ReLU(),\n            nn.Conv1d(in_channels=128, out_channels=128, kernel_size=5, padding='same'),\n            nn.BatchNorm1d(128),\n            nn.ReLU(),\n            nn.AvgPool1d(kernel_size=2),\n            nn.Conv1d(in_channels=128, out_channels=128, kernel_size=7, padding='same'),\n            nn.BatchNorm1d(128),\n            nn.ReLU(),\n            nn.AvgPool1d(kernel_size=2),\n            nn.Flatten(),  # Converts to 1D before fully connected layers\n            nn.Linear(128 * ((self.M) // 4), 256),  # Adjust size based on sequence length\n            nn.ReLU(),\n            nn.BatchNorm1d(256),\n            nn.Linear(256, 128),\n            nn.ReLU(),\n            nn.BatchNorm1d(128),\n            nn.Linear(128, 1),\n            nn.Sigmoid() \n        )\n\n    \n    def forward(self, datas,ids,Seq_ids):\n        #### STEP 1:embeddings\n        datas = datas.float()  # Ensure correct dtype\n        instances=self.transformer_encoder(datas) \n        \n        #### STEP 2: INSTANCE-LEVEL ATTENTION ####\n        # Apply attention mechanisms per bag (over instances_per_bag)\n        A_V = self.attention_V_1(instances)  \n        A_U = self.attention_U_1(instances)  \n        A = self.attention_w_1(A_V * A_U)\n        A = torch.transpose(A, 1, 0)  \n        inner_bags = torch.unique_consecutive(Seq_ids)\n      \n        output = torch.empty(((len(inner_bags), self.M))).to(device)\n        super_ids = torch.empty(((len(inner_bags))))\n        for i, bag in enumerate(inner_bags):\n            A_vec=F.softmax(A[0][Seq_ids == bag],dim=0)\n            output[i] = torch.matmul(A_vec, instances[Seq_ids == bag])\n            super_ids[i]=ids[Seq_ids == bag][0]\n        \n        ### STEP 3: BAG-LEVEL ATTENTION ####\n        A_V_2 = self.attention_V_2(output)  \n        A_U_2 = self.attention_U_2(output)  \n        A_2 = self.attention_w_2(A_V_2 * A_U_2)  \n        A_2 = torch.transpose(A_2, 1,0)   \n\n      \n        outer_bags = torch.unique_consecutive(super_ids)\n        output2 = torch.empty(((len(outer_bags), self.M))).to(device)\n\n        for i, bag in enumerate(outer_bags):\n            A_vec_2=F.softmax(A_2[0][super_ids == bag],dim=0)\n            output2[i] = torch.matmul(A_vec_2, output[super_ids == bag])\n\n        \n        \n        ### STEP 4: CLASSIFICATION ####\n        # output2 = output2.view(output2.shape[0], -1)  # Flatten over bags_per_bag for classification\n        output2 = output2.unsqueeze(1)  # Add a channel dimension\n\n\n        Y_prob = self.classifier(output2)  # Shape: [batch_size, 1]\n        Y_hat = torch.ge(Y_prob, 0.5).float()  # Convert probabilities to binary predictions\n        return Y_prob, Y_hat, A","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T18:19:39.507920Z","iopub.execute_input":"2025-06-05T18:19:39.508135Z","iopub.status.idle":"2025-06-05T18:19:39.531611Z","shell.execute_reply.started":"2025-06-05T18:19:39.508118Z","shell.execute_reply":"2025-06-05T18:19:39.530698Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"class MILDataset(Dataset):\n    def __init__(self, datas, ids, seq_ids, labels):\n        self.datas = datas  # Instance features\n        self.ids = ids # Virus (outer bag) IDs\n        self.seq_ids = seq_ids  # Sequence (inner bag) IDs\n        self.labels = labels.to(\"cpu\")  # Labels at the virus (outer bag) level\n\n        # Unique IDs for outer bags (viruses) and their indices\n        self.unique_virus_ids, self.virus_indices = torch.unique(self.ids, return_inverse=True)\n        \n        # Unique IDs for inner bags (sequences) and their indices\n        self.unique_seq_ids, self.seq_indices = torch.unique(self.seq_ids, return_inverse=True)\n\n        # Mapping from virus to instance indices  2d array each list is the virus data indecies\n        self.virus_bag_indices_list = [torch.where(self.virus_indices == i)[0].to(\"cpu\") for i in tqdm(range(len(self.unique_virus_ids)))]\n\n        # Mapping from sequence to instance indices 2d array each list is the seq data indecies\n        self.seq_bag_indices_list = [torch.where(self.seq_indices == i)[0].to(\"cpu\") for i in tqdm( range(len(self.unique_seq_ids)))]\n\n        # Labels assigned at the virus level (each virus gets one label)\n        self.virus_labels = [self.labels[indices[0]] for indices in self.virus_bag_indices_list]\n\n        # Precomputed bag-of-bags structure (virus → [seq])\n        self.virus_seq_map = {}  # Maps virus_id -> list of sequence indices\n        for i, virus_id in tqdm(enumerate(self.unique_virus_ids)):\n            self.virus_seq_map[virus_id.item()] = list((self.seq_ids[self.virus_bag_indices_list[i]].tolist()))\n\n        # Precomputed bag IDs for each virus and sequence\n        self.precomputed_virus_ids = [torch.full((indices.shape[0],), self.unique_virus_ids[i], dtype=torch.long) \n                                      for i, indices in enumerate(self.virus_bag_indices_list)]\n\n      \n        self.datas = self.datas.cpu()\n\n\n    def __len__(self):\n        return len(self.unique_virus_ids)  # Number of unique viruses (outer bags)\n\n    def __getitem__(self, index):\n        \"\"\" Return outer bag (virus), inner bags (sequences), and instance-level data. \"\"\"\n        \n        # Get all instance indices belonging to this virus\n        virus_instance_indices = self.virus_bag_indices_list[index]\n        # Retrieve instance-level data\n        virus_data = self.datas[virus_instance_indices]\n        virus_label = self.virus_labels[index]\n        virus_id = self.precomputed_virus_ids[index]\n        # Find which sequences belong to this virus\n       \n        seq_ids_in_virus = self.virus_seq_map[virus_id[0].item()]\n\n        return {\n            \"virus_id\": virus_id,\n            \"virus_data\": virus_data,\n            \"virus_label\": virus_label,\n            \"seq_id\": seq_ids_in_virus\n        }\n\n\ndef collate_fn(batch):\n    \"\"\" Custom collate function for Bag-of-Bags MIL \"\"\"\n\n    batch_size = len(batch)\n\n    all_virus_ids = []\n    all_virus_data = []\n    all_virus_labels = []\n    all_virus_seq_ids = []\n   \n\n    for item in batch:\n        virus_id = item[\"virus_id\"].tolist()\n        virus_data = item[\"virus_data\"].tolist()\n        virus_label = item[\"virus_label\"]\n        seq_id = item[\"seq_id\"]\n\n        all_virus_seq_ids.extend(seq_id)\n        all_virus_ids.extend(virus_id)\n        all_virus_data.extend(virus_data)\n        all_virus_labels.append(virus_label)\n    \n    # Convert to tensors\n    batch_virus_labels = torch.tensor(all_virus_labels, dtype=torch.float)\n    batch_seq_ids = torch.tensor(all_virus_seq_ids, dtype=torch.float)\n    batch_virus_datas = torch.tensor(all_virus_data, dtype=torch.float)\n    batch_virus_ids = torch.tensor(all_virus_ids, dtype=torch.float)\n\n\n    return batch_virus_datas, batch_virus_ids,batch_seq_ids, batch_virus_labels\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T18:19:39.532869Z","iopub.execute_input":"2025-06-05T18:19:39.533154Z","iopub.status.idle":"2025-06-05T18:19:39.559364Z","shell.execute_reply.started":"2025-06-05T18:19:39.533133Z","shell.execute_reply":"2025-06-05T18:19:39.558475Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def train(epoch,dataloader):\n    model.train()\n    running_loss=0.\n    acc=0\n    human=0\n    animal=0\n    total_samples=0\n    \n    for batch_data, batch_ids,batch_seq_ids, batch_labels in tqdm(dataloader, desc=\"Processing Batches\"):\n        batch_data,batch_ids,batch_seq_ids, batch_labels  = batch_data.to(device), batch_ids.to(device),batch_seq_ids.to(device), batch_labels.to(device)\n        Y_prob, Y_hat, A =model(batch_data,batch_ids,batch_seq_ids)\n        Y_prob=Y_prob.squeeze(1)\n        Y_hat = Y_hat.view_as(batch_labels)\n        loss = criterion(Y_prob, batch_labels)\n        # Optimizer step\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item()\n        acc += ((Y_hat == batch_labels).sum().item())\n        total_samples += batch_labels.size(0)  # Track the total number of samples processed\n        human+=np.sum(Y_hat.cpu().numpy() == 0)\n        animal+=np.sum(Y_hat.cpu().numpy() == 1)\n    print(f'Epoch: {epoch}, Loss: {running_loss:.4f}, LR: {scheduler.get_last_lr()}')\n    acc=acc/total_samples*100\n    print(f'acc: {acc:.1f}%')\n    print(\"human = \",human)\n    print(\"animal = \",animal)\n    return running_loss","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-05T18:19:39.560094Z","iopub.execute_input":"2025-06-05T18:19:39.560300Z","iopub.status.idle":"2025-06-05T18:19:39.584703Z","shell.execute_reply.started":"2025-06-05T18:19:39.560281Z","shell.execute_reply":"2025-06-05T18:19:39.584024Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def plot_confusion_matrix(true_labels, pred_labels, class_names=[\"Human\", \"Animal\"]):\n    cm = confusion_matrix(true_labels, pred_labels)\n    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n\n    plt.figure(figsize=(6,6))\n    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n    plt.title(\"Confusion Matrix\")\n    plt.xlabel(\"Predicted Label\")\n    plt.ylabel(\"True Label\")\n    plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T18:19:39.585416Z","iopub.execute_input":"2025-06-05T18:19:39.585674Z","iopub.status.idle":"2025-06-05T18:19:39.607402Z","shell.execute_reply.started":"2025-06-05T18:19:39.585654Z","shell.execute_reply":"2025-06-05T18:19:39.606825Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def plot_roc_curve(true_labels, pred_labels):\n    # Binarize for ROC\n    true_bin = label_binarize(true_labels, classes=[0, 1])\n    pred_bin = label_binarize(pred_labels, classes=[0, 1])\n\n    fpr, tpr, _ = roc_curve(true_bin, pred_bin)\n    roc_auc = auc(fpr, tpr)\n\n    plt.figure()\n    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f\"ROC curve (AUC = {roc_auc:.2f})\")\n    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n    plt.xlabel(\"False Positive Rate\")\n    plt.ylabel(\"True Positive Rate\")\n    plt.title(\"Receiver Operating Characteristic (ROC)\")\n    plt.legend(loc=\"lower right\")\n    plt.grid(True)\n    plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T18:19:39.608231Z","iopub.execute_input":"2025-06-05T18:19:39.608503Z","iopub.status.idle":"2025-06-05T18:19:39.623383Z","shell.execute_reply.started":"2025-06-05T18:19:39.608484Z","shell.execute_reply":"2025-06-05T18:19:39.622771Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def test(dataloader):\n    # print(len(labels))\n    model.eval()\n    acc=0\n    human=0\n    animal=0\n    total_samples=0\n    output=[]\n    true_lables=[]\n    with torch.no_grad():\n         for batch_data, batch_ids,batch_seq_ids, batch_labels in tqdm(dataloader, desc=\"Processing Batches\"):\n            batch_data,batch_ids,batch_seq_ids, batch_labels  = batch_data.to(device), batch_ids.to(device),batch_seq_ids.to(device), batch_labels.to(device)\n            Y_prob, Y_hat, A =model(batch_data,batch_ids,batch_seq_ids)         \n            output += Y_hat.cpu().tolist()\n            true_lables += batch_labels.cpu().tolist()\n            Y_prob=Y_prob.squeeze(1)\n            Y_hat = Y_hat.view_as(batch_labels)\n            acc += ((Y_hat == batch_labels).sum().item())\n            human+=np.sum(Y_hat.cpu().numpy() == 0)\n            animal+=np.sum(Y_hat.cpu().numpy() == 1)\n            total_samples += batch_labels.size(0)  # Track the total number of samples processed\n\n    acc=acc/total_samples*100\n    print(f'acc: {acc:.1f}%')\n    # print(\"human = \",human)\n    # print(\"animal = \",animal)\n    print(\"\\nClassification Report:\")\n    print(classification_report(true_lables, output, target_names=[\"Human\", \"Animal\"]))\n\n    plot_confusion_matrix(true_lables, output)\n    # plot_roc_curve(true_lables, output)\n\n    return output,true_lables","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T18:19:39.624115Z","iopub.execute_input":"2025-06-05T18:19:39.624458Z","iopub.status.idle":"2025-06-05T18:19:39.648062Z","shell.execute_reply.started":"2025-06-05T18:19:39.624429Z","shell.execute_reply":"2025-06-05T18:19:39.647405Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# read dataset\nfile_name_original_datas=\"/kaggle/input/ncbi-data-csv/ncbi_cleaned_train_data.csv\"\nfile_name_test_datas=\"/kaggle/input/ncbi-data-csv/ncbi_cleaned_test_data.csv\"\ngasaid_test_file_name=\"/kaggle/input/ncbi-data-csv/gasaid_cleaned_test_data.csv\"\n\n\ndf=read_data_from_file(file_name_original_datas)\ndf_test=read_data_from_file(file_name_test_datas)\n\ndf_gasaid=read_data_from_file(gasaid_test_file_name)\n\n# get the length of the longest seq\nllongest=max(df['Length'])\nlshortest=min(df['Length'])\nprint(\"llongest\",llongest)\nllongest=max(df['Length'])\nprint(\"lshortest\",lshortest)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T18:19:39.648869Z","iopub.execute_input":"2025-06-05T18:19:39.649067Z","iopub.status.idle":"2025-06-05T18:19:41.284144Z","shell.execute_reply.started":"2025-06-05T18:19:39.649050Z","shell.execute_reply":"2025-06-05T18:19:41.283313Z"}},"outputs":[{"name":"stdout","text":"llongest 775\nlshortest 202\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"n=193\nlower_bound = int(llongest / n)\nupper_bound = int(llongest - n + 1)\nl_sub_array=np.arange(lower_bound, upper_bound + 1)\nl_sub=lshortest-n+1\nif l_sub not in l_sub_array:\n    print(\"error ASW\")\nprint(l_sub)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T18:19:41.285099Z","iopub.execute_input":"2025-06-05T18:19:41.285449Z","iopub.status.idle":"2025-06-05T18:19:41.290490Z","shell.execute_reply.started":"2025-06-05T18:19:41.285418Z","shell.execute_reply":"2025-06-05T18:19:41.289418Z"}},"outputs":[{"name":"stdout","text":"10\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"\ndf[\"Class\"] = df[\"Class\"].str.lower()  #Ensure consistent casing\n\nlabels = np.array((df[\"Class\"] != \"human\").astype(int))\n\nids=df[\"Virus_ID\"]\nseq_ids=df[\"Seq_ID\"]+\" \"+df[\"Virus_ID\"]\n\n# convert string id to numeric\n_,ids = np.unique(ids, return_inverse=True)\n_,seq_ids = np.unique(seq_ids, return_inverse=True)\n\n\n\n\ndf_test[\"Class\"] = df_test[\"Class\"].str.lower()  #Ensure consistent casing\ntest_labels = np.array((df_test[\"Class\"] != \"human\").astype(int))\n\ntest_ids=df_test[\"Virus_ID\"]\ntest_seq_ids=df_test[\"Seq_ID\"]+\" \"+df_test[\"Virus_ID\"]\n\n# convert test string id to numeric\n_,test_ids = np.unique(test_ids, return_inverse=True)\n_,test_seq_ids = np.unique(seq_ids, return_inverse=True)\ntest_datas = df_test['Sequence']\n\n\n#gasaid test\ndf_gasaid[\"Class\"] = df_gasaid[\"Class\"].str.lower()  #Ensure consistent casing\ngasaid_test_labels = np.array((df_gasaid[\"Class\"] != \"human\").astype(int))\n\ngasaid_test_ids=df_gasaid[\"Virus_ID\"]\ngasaid_test_seq_ids=df_gasaid[\"Seq_ID\"]+\" \"+df_gasaid[\"Virus_ID\"]\n\n# convert test string id to numeric\n_,gasaid_test_ids = np.unique(gasaid_test_ids, return_inverse=True)\n_,gasaid_test_seq_ids = np.unique(gasaid_test_seq_ids, return_inverse=True)\ngasaid_test_datas = df_gasaid['Sequence']\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T18:19:41.294003Z","iopub.execute_input":"2025-06-05T18:19:41.294309Z","iopub.status.idle":"2025-06-05T18:19:41.487371Z","shell.execute_reply.started":"2025-06-05T18:19:41.294286Z","shell.execute_reply":"2025-06-05T18:19:41.486638Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"datas=df[\"Sequence\"]\n# Get unique bag IDs\nunique_bag_ids = np.unique(ids)\n\n# Split bag IDs into train and test\ntrain_ids, val_ids = train_test_split(unique_bag_ids, test_size=0.2, random_state=42)\n\n# Get indices corresponding to train/test bag IDs\ntrain_indices = np.where(np.isin(ids, train_ids))[0]\nval_indices = np.where(np.isin(ids, val_ids))[0]\n\n# # Create train data\ntrain_datas = datas[train_indices]\ntrain_ids = ids[train_indices]\ntrain_seq_ids = seq_ids[train_indices]\ntrain_labels = labels[train_indices]\n\n\n\n# # Create val data\nval_datas = datas[val_indices]\nval_ids = ids[val_indices]\nval_seq_ids = seq_ids[val_indices]\nval_labels = labels[val_indices]\n\nprint(train_datas.shape)\nprint(val_datas.shape)\nprint(test_datas.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T18:19:41.489781Z","iopub.execute_input":"2025-06-05T18:19:41.490055Z","iopub.status.idle":"2025-06-05T18:19:41.511263Z","shell.execute_reply.started":"2025-06-05T18:19:41.490025Z","shell.execute_reply":"2025-06-05T18:19:41.510247Z"}},"outputs":[{"name":"stdout","text":"(62938,)\n(15599,)\n(1844,)\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# need validation\nSG_EMBEDD_SIZE=30\nSG_WINDOW=5\n# Transformer Parameters\nN_HEAD = 5         # Number of attention heads\nENCODER_N_LAYERS = 2       # Number of transformer layers\nEMBEDDING_SIZE=SG_EMBEDD_SIZE\nINTERMIDIATE_DIM=512\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T18:19:41.512157Z","iopub.execute_input":"2025-06-05T18:19:41.512426Z","iopub.status.idle":"2025-06-05T18:19:41.520859Z","shell.execute_reply.started":"2025-06-05T18:19:41.512403Z","shell.execute_reply":"2025-06-05T18:19:41.520193Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# Apply ASW \n\ntrain_datas = [ASW(sequence,l_sub, n) for sequence in train_datas.tolist()]\n\ntrain_labels= np.repeat(train_labels, n).tolist()\ntrain_ids=np.repeat(train_ids, n).tolist()\ntrain_seq_ids=np.repeat(train_seq_ids, n).tolist()\n\nprint(len(train_datas))\nprint(len(train_datas[0]))\nprint(len(train_datas[0][0]))\n# Apply skip gram\n# Convert k-mers into embeddings\nw2v_model = Word2Vec(sentences=tqdm(train_datas, desc=\" Skip gram Training\"), vector_size=SG_EMBEDD_SIZE, window=SG_WINDOW, sg=1, min_count=1, workers=5)\nw2v_model.save(\"word2vec_skipgram.model\")\n\ntrain_seq_embeddings = np.array([w2v_model.wv[kmer] for kmer in tqdm(train_datas,desc=\"Skip gram inference\")])\ntrain_seq_embeddings = np.array(list(chain.from_iterable(train_seq_embeddings)))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T18:19:41.521580Z","iopub.execute_input":"2025-06-05T18:19:41.521894Z"}},"outputs":[{"name":"stdout","text":"62938\n193\n10\n","output_type":"stream"},{"name":"stderr","text":" Skip gram Training: 100%|██████████| 62938/62938 [00:02<00:00, 30333.74it/s]\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"train_seq_embeddings=torch.tensor(train_seq_embeddings).to(device)\ntrain_ids=torch.tensor(train_ids).to(device)\ntrain_seq_ids=torch.tensor(train_seq_ids).to(device)\ntrain_labels=torch.tensor(train_labels).to(device)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_mildataset = MILDataset(train_seq_embeddings, train_ids,train_seq_ids, train_labels)\ntrain_loader = DataLoader(train_mildataset, batch_size=32, shuffle=True,num_workers=4, collate_fn=collate_fn)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Auto-detect GPU\nmodel = GatedAttention(N_HEAD,ENCODER_N_LAYERS,EMBEDDING_SIZE,INTERMIDIATE_DIM).to(device)  # Move model to GPU\noptimizer = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999))\ncriterion = nn.BCELoss().to(device)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5, verbose=True)\n\n\nprint(f\"Using device: {device}\") \nprint('Start Training')\nfor epoch in range(1, 10+1):\n    loss = train(epoch, train_loader)\n    scheduler.step(loss)  # Update LR based on loss\n    if scheduler.num_bad_epochs >= 5:  # Stop after 10 consecutive non-improving epochs\n        print(f\"Stopping early: No improvement for {scheduler.num_bad_epochs} epochs\")\n        break","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.save(model.state_dict(), \"model_weights.pth\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# model = GatedAttention(N_HEAD, ENCODER_N_LAYERS, EMBEDDING_SIZE, INTERMIDIATE_DIM).to(device)\n# model.load_state_dict(torch.load(\"model_weights.pth\", map_location=device))\n# model.eval()\n# w2v_model = Word2Vec.load(\"/kaggle/working/word2vec_skipgram.model\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import Levenshtein\n\ndef get_most_similar_kmer_fast(kmer, known_kmers):\n    min_dist = float('inf')\n    best_kmer = None\n    for cand in known_kmers:\n        dist = Levenshtein.distance(kmer, cand)\n        if dist < min_dist:\n            min_dist = dist\n            best_kmer = cand\n            if dist == 0:\n                break  # Perfect match\n    return best_kmer\nfrom rapidfuzz import process, fuzz\n\ndef get_most_similar_kmer_fuzzy(kmer, known_kmers):\n    match = process.extractOne(kmer, known_kmers, scorer=fuzz.ratio)\n    return match[0] if match else None\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Apply ASW \n\n# gasaid_test_datas = [ASW(sequence,l_sub, n) for sequence in gasaid_test_datas.tolist()]\n\n# gasaid_test_labels= np.repeat(gasaid_test_labels, n).tolist()\n# gasaid_test_ids=np.repeat(gasaid_test_ids, n).tolist()\n# gasaid_test_seq_ids=np.repeat(gasaid_test_seq_ids, n).tolist()\n\n\n# # Apply skip gram\n# keys_wv=set(list(w2v_model.wv.key_to_index.keys()))\n \n# gasaid_test_seq_embeddings = []\n\n# for kmer_list in tqdm(gasaid_test_datas, desc=\"Skip gram inference\"):\n#     embedded_seq = []\n#     for kmer in kmer_list:\n#         if kmer in keys_wv:\n#             gasaid_test_seq_embeddings.append(w2v_model.wv[kmer])\n#         else:\n#             # Replace with embedding of most similar k-mer\n#             sim_kmer = get_most_similar_kmer_fast(kmer, keys_wv)\n#             gasaid_test_seq_embeddings.append(w2v_model.wv[sim_kmer])\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Apply ASW \n\ntest_datas = [ASW(sequence,l_sub, n) for sequence in test_datas.tolist()]\n\ntest_labels= np.repeat(test_labels, n).tolist()\ntest_ids=np.repeat(test_ids, n).tolist()\ntest_seq_ids=np.repeat(test_seq_ids, n).tolist()\n\n\n# Apply skip gram\nkeys_wv=set(list(w2v_model.wv.key_to_index.keys()))\n   \n# Convert k-mers into embeddings\ntest_seq_embeddings = np.array([\n    w2v_model.wv[k] if k in keys_wv else np.zeros(30)\n    for kmer in tqdm(test_datas, desc=\"Skip gram inference\")  \n    for k in kmer  # kmer should be defined first\n])\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Apply ASW \n\nval_datas = [ASW(sequence,l_sub, n) for sequence in val_datas.tolist()]\n\nval_labels= np.repeat(val_labels, n).tolist()\nval_ids=np.repeat(val_ids, n).tolist()\nval_seq_ids=np.repeat(val_seq_ids, n).tolist()\n\n\n# Apply skip gram\nkeys_wv=set(list(w2v_model.wv.key_to_index.keys()))\n   \n# Convert k-mers into embeddings\nval_seq_embeddings = np.array([\n    w2v_model.wv[k] if k in keys_wv else np.zeros(30)\n    for kmer in tqdm(val_datas, desc=\"Skip gram inference\")  \n    for k in kmer  # kmer should be defined first\n])\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_seq_embeddings=torch.tensor(test_seq_embeddings).to(device)\ntest_ids=torch.tensor(test_ids).to(device)\ntest_seq_ids=torch.tensor(test_seq_ids).to(device)\ntest_labels=torch.tensor(test_labels).to(device)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"val_seq_embeddings=torch.tensor(val_seq_embeddings).to(device)\nval_ids=torch.tensor(val_ids).to(device)\nval_seq_ids=torch.tensor(val_seq_ids).to(device)\nval_labels=torch.tensor(val_labels).to(device)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# gasaid_test_seq_embeddings=torch.tensor(gasaid_test_seq_embeddings).to(device)\n# gasaid_test_ids=torch.tensor(gasaid_test_ids).to(device)\n# gasaid_test_seq_ids=torch.tensor(gasaid_test_seq_ids).to(device)\n# gasaid_test_labels=torch.tensor(gasaid_test_labels).to(device)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# gasaid_mildataset = MILDataset(gasaid_test_seq_embeddings, gasaid_test_ids,gasaid_test_seq_ids, gasaid_test_labels)\n# gasaid_loader = DataLoader(gasaid_mildataset, batch_size=32, shuffle=True,num_workers=0, collate_fn=collate_fn)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_mildataset = MILDataset(test_seq_embeddings, test_ids,test_seq_ids, test_labels)\ntest_loader = DataLoader(test_mildataset, batch_size=32, shuffle=True,num_workers=0, collate_fn=collate_fn)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"val_mildataset = MILDataset(val_seq_embeddings, val_ids,val_seq_ids, val_labels)\nval_loader = DataLoader(val_mildataset, batch_size=32, shuffle=True,num_workers=0, collate_fn=collate_fn)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print('Start Testing on test data')\nout2=test(test_loader)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print('Start Testing on validation data')\nout2=test(val_loader)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# print('Start Testing on test data')\n# out2=test(gasaid_loader)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print('Start Testing on train')\nout=test(train_loader)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}